{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZh3qfeNyzHF",
        "outputId": "ecfdc3e2-a30a-4094-c819-7d48ca4a979b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dvl_vm8CylS-"
      },
      "outputs": [],
      "source": [
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import os\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchsummary\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "import time\n",
        "import zipfile\n",
        "import subprocess\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def seed_everything(seed=42):\n",
        "    \"\"\"\n",
        "    모든 랜덤 시드를 주어진 값으로 고정합니다.\n",
        "    \"\"\"\n",
        "    random.seed(seed)  # Python random 모듈\n",
        "    np.random.seed(seed)  # Numpy 랜덤 시드\n",
        "    torch.manual_seed(seed)  # PyTorch 랜덤 시드\n",
        "    torch.cuda.manual_seed(seed)  # GPU를 위한 PyTorch 랜덤 시드\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티 GPU를 위한 PyTorch 랜덤 시드\n",
        "\n",
        "seed_everything()"
      ],
      "metadata": {
        "id": "xOpCEwZSy1-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class CustomDataset(torch.utils.data.Dataset):\n",
        "#     def __init__(self, image_zip_paths, label_zip_paths, cache_dir, transform=None, workers=4):\n",
        "#         super().__init__()\n",
        "#         self.image_zip_paths = image_zip_paths\n",
        "#         self.label_zip_paths = label_zip_paths\n",
        "#         self.cache_dir = cache_dir\n",
        "#         self.transform = transform\n",
        "#         self.workers = workers\n",
        "\n",
        "#         if not os.path.exists(self.cache_dir):\n",
        "#             os.makedirs(self.cache_dir, exist_ok=True)\n",
        "\n",
        "#         self.image_names = {}\n",
        "#         self.label_names = {}\n",
        "#         self.image_list = []\n",
        "\n",
        "#         self._prepare()\n",
        "\n",
        "#     def _extract_and_cache(self, zip_path, file_name, cache_file_path, attempts=3):\n",
        "#         if os.path.exists(cache_file_path):\n",
        "#             return True\n",
        "\n",
        "#         command = [\"unzip\", \"-o\", zip_path, file_name, \"-d\", os.path.dirname(cache_file_path)]\n",
        "\n",
        "#         for attempt in range(attempts):\n",
        "#             result = subprocess.run(command, check=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "#             # 성공적으로 압축 해제되었거나, 경고만 있는 경우\n",
        "#             if result.returncode == 0 or \"warning\" in result.stderr.decode().lower():\n",
        "#                 return True\n",
        "#             else:\n",
        "#                 # 오류 메시지가 있고, 재시도 횟수가 남아있는 경우\n",
        "#                 print(f\"Attempt {attempt + 1}: Error unzipping file => {zip_path}\")\n",
        "#                 time.sleep(2 ** attempt)\n",
        "\n",
        "#         # 모든 시도가 실패한 경우\n",
        "#         print(f\"Failed to extract {file_name}\")\n",
        "#         return False\n",
        "\n",
        "#     def _prepare(self):\n",
        "#         max_tries = 3\n",
        "#         wait_seconds = 10\n",
        "\n",
        "#         # 각 zip 파일에 대한 재시도 횟수를 추적\n",
        "#         retries = {zip_path: 0 for zip_path in self.image_zip_paths + self.label_zip_paths}\n",
        "\n",
        "#         # 전체 압축 파일 리스트\n",
        "#         to_process = [(zip_path, '.png') for zip_path in self.image_zip_paths] + [(zip_path, '.json') for zip_path in self.label_zip_paths]\n",
        "\n",
        "#         while to_process:\n",
        "#             # 병렬처리\n",
        "#             with ThreadPoolExecutor(max_workers=self.workers) as executor:\n",
        "#                 future_to_zip_path = {\n",
        "#                     executor.submit(self._process_zip, zip_path, file_extension): (zip_path, file_extension)\n",
        "#                     for zip_path, file_extension in to_process\n",
        "#                 }\n",
        "\n",
        "#                 # 처리 중 예외 발생 시 재시도할 작업 목록\n",
        "#                 to_retry = []\n",
        "\n",
        "#                 # future 객체의 작업완료 상황을 모니터링\n",
        "#                 for future in as_completed(future_to_zip_path):\n",
        "#                     zip_path, file_extension = future_to_zip_path[future]\n",
        "\n",
        "#                     try:\n",
        "#                         success = future.result()\n",
        "#                         if not success:\n",
        "#                             raise Exception(f\"Failed to process {zip_path}\")\n",
        "\n",
        "#                     except OSError as e: # 구글드라이브와의 연결로 인한 예외처리\n",
        "#                         if e.errno == 107 and retries[zip_path] < max_tries:\n",
        "#                             print(f\"OSError [Errno 107] => {zip_path}\")\n",
        "#                             to_retry.append((zip_path, file_extension))\n",
        "#                             retries[zip_path] += 1\n",
        "#                             time.sleep(wait_seconds)  # 각 재시도 사이에 대기\n",
        "#                             wait_seconds *= 2  # 대기 시간 증가\n",
        "#                         else:\n",
        "#                             print(f\"Unexpected Error : {zip_path}: {e}\")\n",
        "\n",
        "#                     except Exception as e:\n",
        "#                         print(f\"Exception processing {zip_path}: {e}\")\n",
        "\n",
        "#                 # 재시도할 작업이 있으면 to_process 업데이트\n",
        "#                 to_process = to_retry if to_retry else []\n",
        "\n",
        "#         self.image_list = sorted(self.image_names.keys())\n",
        "\n",
        "#     def _process_zip(self, zip_path, file_extension):\n",
        "#         success = True\n",
        "#         with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "\n",
        "#             for file_name in sorted(zip_ref.namelist()):\n",
        "\n",
        "#                 if file_name.endswith(file_extension):\n",
        "#                     base_name = os.path.splitext(os.path.basename(file_name))[0].lstrip('_')  # 확장자 제외 파일 기본 이름\n",
        "\n",
        "#                     # 데이터 접근시 사용할 경로\n",
        "#                     cache_file_path = os.path.join(self.cache_dir, os.path.basename(zip_path).replace('.zip', ''), file_name.replace('/', '_').lstrip('_'))\n",
        "\n",
        "#                     if file_extension == '.png':\n",
        "#                         self.image_names[base_name.lower()] = cache_file_path\n",
        "#                     else:\n",
        "#                         self.label_names[base_name.lower()] = cache_file_path\n",
        "\n",
        "#                     extract_success = self._extract_and_cache(zip_path, file_name, cache_file_path)\n",
        "#                     success = success and extract_success\n",
        "\n",
        "#         return success\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.image_names)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         # 파일 이름을 키 리스트에서 추출\n",
        "#         base_name = self.image_list[idx]\n",
        "\n",
        "#         image_path = self.image_names.get(base_name)\n",
        "\n",
        "#         try:\n",
        "#             image = Image.open(image_path)\n",
        "#         except Exception as e:\n",
        "#             return None\n",
        "\n",
        "#         label_path = self.label_names.get(base_name)\n",
        "#         with open(label_path, 'r') as f:\n",
        "#             label_data = json.load(f)\n",
        "\n",
        "#         age_past = label_data['age_past']\n",
        "#         gender = label_data['gender']\n",
        "#         box = label_data['annotation'][0]['box']\n",
        "\n",
        "#         image = image.crop((box['x'], box['y'], box['x'] + box['w'], box['y'] + box['h']))\n",
        "\n",
        "#         if self.transform:\n",
        "#             image = self.transform(image)\n",
        "\n",
        "#         gender_label = 0 if gender == 'male' else 1\n",
        "\n",
        "#         label = {'age_past': age_past, 'gender': gender_label}\n",
        "\n",
        "#         return image, label\n"
      ],
      "metadata": {
        "id": "hxiPS2QYy5oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤하게 적용\n",
        "random_transforms = transforms.RandomApply([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "], p=0.5)\n",
        "\n",
        "# 항상 적용\n",
        "always_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.6284, 0.4901, 0.4325], std=[0.1869, 0.1712, 0.1561]),\n",
        "])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    random_transforms,\n",
        "    always_transforms\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    always_transforms\n",
        "])"
      ],
      "metadata": {
        "id": "YEBaVxBizBhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_zip_files(directory):\n",
        "#     return [os.path.join(directory, zip) for zip in os.listdir(directory) if zip.endswith('.zip')] # 리스트를 정렬하면 속도 하락\n",
        "\n",
        "# train_images = '/content/drive/Othercomputers/Home/data_age/data/Training/image'\n",
        "# train_labels = '/content/drive/Othercomputers/Home/data_age/data/Training/label'\n",
        "# train_cache = '/content/cache/train'\n",
        "\n",
        "# val_images = '/content/drive/Othercomputers/Home/data_age/data/Validation/image'\n",
        "# val_labels = '/content/drive/Othercomputers/Home/data_age/data/Validation/label'\n",
        "# val_cache = '/content/cache/val'\n",
        "\n",
        "# train_image_zips = get_zip_files(train_images)\n",
        "# train_label_zips = get_zip_files(train_labels)\n",
        "# val_image_zips = get_zip_files(val_images)\n",
        "# val_label_zips = get_zip_files(val_labels)"
      ],
      "metadata": {
        "id": "89M2Et6MzD-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %time train_dataset = CustomDataset(train_image_zips, train_label_zips, train_cache, transform_train)"
      ],
      "metadata": {
        "id": "ncPB39WUzGK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %time val_dataset = CustomDataset(val_image_zips, val_label_zips, val_cache, transform_val)"
      ],
      "metadata": {
        "id": "1gWXBa90zHtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_root, transform=None):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "\n",
        "        self.items = []  # (이미지 경로, 라벨 경로) 튜플을 저장\n",
        "\n",
        "        # 모든 라벨 파일 경로를 소문자로 변환하여 저장\n",
        "        label_paths_lower = {os.path.join(data_root, path).lower(): path for path in glob.glob(os.path.join(data_root, '*_*/*.json'))}\n",
        "\n",
        "        image_paths = glob.glob(os.path.join(data_root, '*_*/*.png'))  # 이미지 파일 경로 수집\n",
        "        for image_path in image_paths:\n",
        "            base_name = os.path.splitext(os.path.basename(image_path))[0].lower()  # 파일명에서 확장자 제거 및 소문자 변환\n",
        "            label_dir = os.path.dirname(image_path).replace('TS_', 'TL_').replace('VS_', 'VL_').lower()\n",
        "            label_path = os.path.join(label_dir, base_name + '.json')\n",
        "\n",
        "            # 소문자 변환된 라벨 경로로 실제 파일 경로 확인\n",
        "            actual_label_path = label_paths_lower.get(label_path)\n",
        "            if actual_label_path:\n",
        "                self.items.append((base_name, (image_path, actual_label_path)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        base_name, (image_path, label_path) = self.items[idx]\n",
        "\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "        with open(label_path, 'r') as f:\n",
        "            label_data = json.load(f)\n",
        "\n",
        "        age_past = label_data['age_past']\n",
        "        gender = label_data['gender']\n",
        "        box = label_data['annotation'][0]['box']\n",
        "        image = image.crop((box['x'], box['y'], box['x'] + box['w'], box['y'] + box['h']))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        gender_label = 0 if gender == 'male' else 1\n",
        "        label = {'age_past': age_past, 'gender': gender_label}\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "phIO6SUsN11D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_root = '/content/cache/train'\n",
        "val_data_root = '/content/cache/val'\n",
        "train_dataset =  CustomDataset(train_data_root, transform_train)\n",
        "val_dataset =  CustomDataset(val_data_root, transform_val)"
      ],
      "metadata": {
        "id": "ls5PkM55HEUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    batch = [item for item in batch if item is not None]\n",
        "    return torch.utils.data.dataloader.default_collate(batch)"
      ],
      "metadata": {
        "id": "MFjjmH3WzI25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 96\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=8,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=8,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "Au_gG8bVzKEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrMEv7CZzNes",
        "outputId": "c7498971-9570-47ff-f37c-d60ebdc1bf54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Age_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(3, 128, kernel_size=3, padding=1)\n",
        "        self.bn1_1 = nn.BatchNorm2d(128)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(256)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(512)\n",
        "        self.conv3_1x1 = nn.Conv2d(512, 256, kernel_size=1)  # 1x1 컨볼루션 적용\n",
        "        self.bn3_1x1 = nn.BatchNorm2d(256)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # 평균 풀링 레이어를 추가하여 마지막 컨볼루션 레이어의 출력 크기를 감소\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.fc1 = nn.Linear(256, 128)\n",
        "        self.dropout = nn.Dropout(0.5)  # 드롭아웃 비율 조정\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
        "        x = F.relu(self.bn3_1x1(self.conv3_1x1(x)))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = F.relu(self.fc1(self.dropout(x)))\n",
        "        x = self.fc2(x)\n",
        "        x = x.squeeze()\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "LhTbbKObvseZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 배치정규화 적용\n",
        "# class Age_Net(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.conv1_1 = nn.Conv2d(3, 128, kernel_size=3)\n",
        "#         self.bn1_1 = nn.BatchNorm2d(128)\n",
        "#         self.conv1_2 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "#         self.bn1_2 = nn.BatchNorm2d(128)\n",
        "#         self.conv1_3 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "#         self.bn1_3 = nn.BatchNorm2d(128)\n",
        "\n",
        "#         self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "#         self.conv2_1 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "#         self.bn2_1 = nn.BatchNorm2d(128)\n",
        "#         self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "#         self.bn2_2 = nn.BatchNorm2d(128)\n",
        "#         self.conv2_3 = nn.Conv2d(128, 128, kernel_size=3)\n",
        "#         self.bn2_3 = nn.BatchNorm2d(128)\n",
        "\n",
        "#         self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3)\n",
        "#         self.bn3_1 = nn.BatchNorm2d(256)\n",
        "#         self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3)\n",
        "#         self.bn3_2 = nn.BatchNorm2d(256)\n",
        "#         self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3)\n",
        "#         self.bn3_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3)\n",
        "#         self.bn4_1 = nn.BatchNorm2d(512)\n",
        "#         self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3)\n",
        "#         self.bn4_2 = nn.BatchNorm2d(512)\n",
        "#         self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3)\n",
        "#         self.bn4_3 = nn.BatchNorm2d(512)\n",
        "\n",
        "#         self.fc1 = nn.Linear(512 * 7 * 7, 512)\n",
        "#         self.dropout = nn.Dropout(0.25)\n",
        "#         self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
        "#         x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
        "#         x = F.relu(self.bn1_3(self.conv1_3(x)))\n",
        "#         x = self.pool(x)\n",
        "\n",
        "#         x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
        "#         x = F.relu(self.bn2_2(self.conv2_2(x)))\n",
        "#         x = F.relu(self.bn2_3(self.conv2_3(x)))\n",
        "#         x = self.pool(x)\n",
        "\n",
        "#         x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
        "#         x = F.relu(self.bn3_2(self.conv3_2(x)))\n",
        "#         x = F.relu(self.bn3_3(self.conv3_3(x)))\n",
        "#         x = self.pool(x)\n",
        "\n",
        "#         x = F.relu(self.bn4_1(self.conv4_1(x)))\n",
        "#         x = F.relu(self.bn4_2(self.conv4_2(x)))\n",
        "#         x = F.relu(self.bn4_3(self.conv4_3(x)))\n",
        "#         x = self.pool(x)\n",
        "\n",
        "#         x = x.view(-1, 512 * 7 * 7)\n",
        "#         x = F.relu(self.fc1(self.dropout(x)))\n",
        "#         x = self.fc2(x)\n",
        "#         x = x.squeeze()\n",
        "#         return x\n"
      ],
      "metadata": {
        "id": "kjscnQ4SzRby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Gender_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 36, kernel_size=3)\n",
        "        self.bn1 = nn.BatchNorm2d(36)\n",
        "        self.conv2 = nn.Conv2d(36, 64, kernel_size=3)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3)\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(512 * 4 * 4, 512)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
        "        x = self.pool(F.relu(self.bn5(self.conv5(x))))\n",
        "\n",
        "        x = x.view(-1, 512 * 4 * 4)\n",
        "        x = F.relu(self.fc1(self.dropout(x)))\n",
        "        x = self.fc2(x)\n",
        "        x = x.squeeze()\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ymvVq7r8zTRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "age_model = Age_Net().to(device)\n",
        "torchsummary.summary(age_model, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO714RHOzU_D",
        "outputId": "98eb2f7f-5d9c-4c88-e899-35aaada9b1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [-1, 128, 224, 224]           3,584\n",
            "       BatchNorm2d-2        [-1, 128, 224, 224]             256\n",
            "         MaxPool2d-3        [-1, 128, 112, 112]               0\n",
            "            Conv2d-4        [-1, 256, 112, 112]         295,168\n",
            "       BatchNorm2d-5        [-1, 256, 112, 112]             512\n",
            "         MaxPool2d-6          [-1, 256, 56, 56]               0\n",
            "            Conv2d-7          [-1, 512, 56, 56]       1,180,160\n",
            "       BatchNorm2d-8          [-1, 512, 56, 56]           1,024\n",
            "            Conv2d-9          [-1, 256, 56, 56]         131,328\n",
            "      BatchNorm2d-10          [-1, 256, 56, 56]             512\n",
            "        MaxPool2d-11          [-1, 256, 28, 28]               0\n",
            "AdaptiveAvgPool2d-12            [-1, 256, 1, 1]               0\n",
            "          Dropout-13                  [-1, 256]               0\n",
            "           Linear-14                  [-1, 128]          32,896\n",
            "           Linear-15                    [-1, 1]             129\n",
            "================================================================\n",
            "Total params: 1,645,569\n",
            "Trainable params: 1,645,569\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 203.66\n",
            "Params size (MB): 6.28\n",
            "Estimated Total Size (MB): 210.51\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gender_model = Gender_Net().to(device)\n",
        "torchsummary.summary(gender_model, (3, 224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi-0Y-GBzXJ0",
        "outputId": "a6065870-fcf6-4657-c0f5-f497eaf35b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 36, 222, 222]           1,008\n",
            "       BatchNorm2d-2         [-1, 36, 222, 222]              72\n",
            "         MaxPool2d-3         [-1, 36, 110, 110]               0\n",
            "            Conv2d-4         [-1, 64, 108, 108]          20,800\n",
            "       BatchNorm2d-5         [-1, 64, 108, 108]             128\n",
            "         MaxPool2d-6           [-1, 64, 53, 53]               0\n",
            "            Conv2d-7          [-1, 128, 51, 51]          73,856\n",
            "       BatchNorm2d-8          [-1, 128, 51, 51]             256\n",
            "         MaxPool2d-9          [-1, 128, 25, 25]               0\n",
            "           Conv2d-10          [-1, 256, 23, 23]         295,168\n",
            "      BatchNorm2d-11          [-1, 256, 23, 23]             512\n",
            "        MaxPool2d-12          [-1, 256, 11, 11]               0\n",
            "           Conv2d-13            [-1, 512, 9, 9]       1,180,160\n",
            "      BatchNorm2d-14            [-1, 512, 9, 9]           1,024\n",
            "        MaxPool2d-15            [-1, 512, 4, 4]               0\n",
            "          Dropout-16                 [-1, 8192]               0\n",
            "           Linear-17                  [-1, 512]       4,194,816\n",
            "           Linear-18                    [-1, 1]             513\n",
            "================================================================\n",
            "Total params: 5,768,313\n",
            "Trainable params: 5,768,313\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 51.91\n",
            "Params size (MB): 22.00\n",
            "Estimated Total Size (MB): 74.49\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.optim as optim\n",
        "\n",
        "opt_age = optim.Adam(age_model.parameters(), lr=0.0003)\n",
        "age_lr_scheduler = ReduceLROnPlateau(opt_age, mode='min', verbose=True)\n",
        "\n",
        "opt_gender = optim.Adam(gender_model.parameters(), lr=0.0003)\n",
        "gender_lr_scheduler = ReduceLROnPlateau(opt_gender, mode='min', verbose=True)"
      ],
      "metadata": {
        "id": "A9WJHuLMzYno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.best_loss = np.inf\n",
        "        self.early_stop = False\n",
        "        self.counter = 0\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss - val_loss > self.delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                if self.verbose:\n",
        "                    print(\"Early stopping\")\n",
        "\n",
        "early_stopping = EarlyStopping(patience=5, verbose=True)"
      ],
      "metadata": {
        "id": "oW99Zv5jzal6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop_age(dataloader, model, loss_fn, optimizer, epoch):\n",
        "    model.train()\n",
        "    size = len(dataloader.dataset)\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()  # 에포크 시작 시간\n",
        "\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        batch_start_time = time.time()  # 배치 처리 시작 시간\n",
        "        x, y = x.to(device), y['age_past'].float().to(device)\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred.squeeze(), y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_process_time = time.time() - batch_start_time\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            processed = (batch + 1) * len(x)\n",
        "            print(f'Epoch {epoch+1} : [{processed} / {size}] loss : {loss.item()}, Batch time: {batch_process_time:.4f} sec')\n",
        "\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch+1} finished, Total Epoch time: {epoch_time:.4f} sec\")\n",
        "    return average_loss\n"
      ],
      "metadata": {
        "id": "-AMQ7thKzb1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_loop_age(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y['age_past'].float().to(device)\n",
        "            pred = model(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(dataloader)\n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "mkmNGdjszdT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(epoch, model, optimizer, path):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, path)"
      ],
      "metadata": {
        "id": "_pM6o3a3zezY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "for epoch in range(30):\n",
        "    age_loss = train_loop_age(train_loader, age_model, nn.MSELoss(), opt_age, epoch)\n",
        "    val_loss = validation_loop_age(val_loader, age_model, nn.MSELoss(), device)\n",
        "    age_lr_scheduler.step(val_loss)\n",
        "\n",
        "    early_stopping(val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        save_model(epoch, age_model, opt_age, '/content/drive/MyDrive/DL_DATA/Model/norm/age_model_norm_checkpoint.pth')\n",
        "        break\n",
        "\n",
        "    save_model(epoch, age_model, opt_age, f'/content/drive/MyDrive/DL_DATA/Model/norm/age_model_norm_checkpoint_epoch_{epoch+1}.pth')\n",
        "    print(f'Epoch : {epoch+1}, Loss : {age_loss}, Val_loss : {val_loss}')\n",
        "\n",
        "total_time = time.time() - start\n",
        "\n",
        "# 전체 학습 시간 출력\n",
        "hours, rem = divmod(total_time, 3600)\n",
        "minutes, seconds = divmod(rem, 60)\n",
        "print(\"Total training time: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OV-DU_DbzjI6",
        "outputId": "a27b77d9-818b-41bb-ad03-f1c3840783e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 : [96 / 40150] loss : 710.0734252929688, Batch time: 1.7963 sec\n",
            "Epoch 1 : [1056 / 40150] loss : 691.0452880859375, Batch time: 1.1965 sec\n",
            "Epoch 1 : [2016 / 40150] loss : 397.5665283203125, Batch time: 1.2037 sec\n",
            "Epoch 1 : [2976 / 40150] loss : 440.4202575683594, Batch time: 1.2074 sec\n",
            "Epoch 1 : [3936 / 40150] loss : 493.1903076171875, Batch time: 1.1995 sec\n",
            "Epoch 1 : [4896 / 40150] loss : 213.16488647460938, Batch time: 1.1978 sec\n",
            "Epoch 1 : [5856 / 40150] loss : 240.6251220703125, Batch time: 1.2018 sec\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 : [6816 / 40150] loss : 216.26339721679688, Batch time: 1.2007 sec\n",
            "Epoch 1 : [7776 / 40150] loss : 259.8624572753906, Batch time: 1.1935 sec\n",
            "Epoch 1 : [8736 / 40150] loss : 188.62210083007812, Batch time: 1.1980 sec\n",
            "Epoch 1 : [9696 / 40150] loss : 221.4093475341797, Batch time: 1.1867 sec\n",
            "Epoch 1 : [10656 / 40150] loss : 147.3946533203125, Batch time: 1.4918 sec\n",
            "Epoch 1 : [11616 / 40150] loss : 193.8997802734375, Batch time: 1.4703 sec\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 : [12576 / 40150] loss : 192.81228637695312, Batch time: 1.4908 sec\n",
            "Epoch 1 : [13536 / 40150] loss : 172.88577270507812, Batch time: 1.5024 sec\n",
            "Epoch 1 : [14496 / 40150] loss : 245.886962890625, Batch time: 1.4932 sec\n",
            "Epoch 1 : [15456 / 40150] loss : 165.77456665039062, Batch time: 1.4852 sec\n",
            "Epoch 1 : [16416 / 40150] loss : 174.89431762695312, Batch time: 1.4945 sec\n",
            "Epoch 1 : [17376 / 40150] loss : 183.56419372558594, Batch time: 1.4936 sec\n",
            "Epoch 1 : [18336 / 40150] loss : 172.33642578125, Batch time: 1.4834 sec\n",
            "Epoch 1 : [19296 / 40150] loss : 142.19503784179688, Batch time: 1.4921 sec\n",
            "Epoch 1 : [20256 / 40150] loss : 203.39794921875, Batch time: 1.5041 sec\n",
            "Epoch 1 : [21216 / 40150] loss : 243.62863159179688, Batch time: 1.4985 sec\n",
            "Epoch 1 : [22176 / 40150] loss : 196.03216552734375, Batch time: 1.4927 sec\n",
            "Epoch 1 : [23136 / 40150] loss : 181.86996459960938, Batch time: 1.4966 sec\n",
            "Epoch 1 : [24096 / 40150] loss : 155.40586853027344, Batch time: 1.4881 sec\n",
            "Epoch 1 : [25056 / 40150] loss : 175.9058837890625, Batch time: 1.4795 sec\n",
            "Epoch 1 : [26016 / 40150] loss : 142.49449157714844, Batch time: 1.5000 sec\n",
            "Epoch 1 : [26976 / 40150] loss : 195.42172241210938, Batch time: 1.4688 sec\n",
            "Epoch 1 : [27936 / 40150] loss : 153.66195678710938, Batch time: 1.4955 sec\n",
            "Epoch 1 : [28896 / 40150] loss : 137.7718963623047, Batch time: 1.5138 sec\n",
            "Epoch 1 : [29856 / 40150] loss : 152.9054718017578, Batch time: 1.5057 sec\n",
            "Epoch 1 : [30816 / 40150] loss : 154.1412811279297, Batch time: 1.4890 sec\n",
            "Epoch 1 : [31776 / 40150] loss : 202.8682098388672, Batch time: 1.5156 sec\n",
            "Epoch 1 : [32736 / 40150] loss : 184.14053344726562, Batch time: 1.4873 sec\n",
            "Epoch 1 : [33696 / 40150] loss : 191.62393188476562, Batch time: 1.4958 sec\n",
            "Epoch 1 : [34656 / 40150] loss : 151.4076385498047, Batch time: 1.4837 sec\n",
            "Epoch 1 : [35616 / 40150] loss : 162.94728088378906, Batch time: 1.4723 sec\n",
            "Epoch 1 : [36576 / 40150] loss : 143.81036376953125, Batch time: 1.4833 sec\n",
            "Epoch 1 : [37536 / 40150] loss : 142.23452758789062, Batch time: 1.4939 sec\n",
            "Epoch 1 : [38496 / 40150] loss : 185.4928436279297, Batch time: 1.4829 sec\n",
            "Epoch 1 : [39456 / 40150] loss : 131.53900146484375, Batch time: 1.4911 sec\n",
            "Epoch 1 finished, Total Epoch time: 3335.0356 sec\n",
            "Epoch : 1, Loss : 212.2974793245229, Val_loss : 154.38576752284789\n",
            "Epoch 2 : [96 / 40150] loss : 169.03366088867188, Batch time: 1.4767 sec\n",
            "Epoch 2 : [1056 / 40150] loss : 163.91116333007812, Batch time: 1.4889 sec\n",
            "Epoch 2 : [2016 / 40150] loss : 202.64352416992188, Batch time: 1.4782 sec\n",
            "Epoch 2 : [2976 / 40150] loss : 162.470703125, Batch time: 1.5037 sec\n",
            "Epoch 2 : [3936 / 40150] loss : 173.76243591308594, Batch time: 1.5041 sec\n",
            "Epoch 2 : [4896 / 40150] loss : 207.7793426513672, Batch time: 1.4842 sec\n",
            "Epoch 2 : [5856 / 40150] loss : 206.1587371826172, Batch time: 1.5111 sec\n",
            "Epoch 2 : [6816 / 40150] loss : 172.0235595703125, Batch time: 1.5075 sec\n",
            "Epoch 2 : [7776 / 40150] loss : 124.663818359375, Batch time: 1.4995 sec\n",
            "Epoch 2 : [8736 / 40150] loss : 177.87118530273438, Batch time: 1.4948 sec\n",
            "Epoch 2 : [9696 / 40150] loss : 167.19290161132812, Batch time: 1.5112 sec\n",
            "Epoch 2 : [10656 / 40150] loss : 162.88818359375, Batch time: 1.4887 sec\n",
            "Epoch 2 : [11616 / 40150] loss : 173.12631225585938, Batch time: 1.5004 sec\n",
            "Epoch 2 : [12576 / 40150] loss : 143.4195556640625, Batch time: 1.5084 sec\n",
            "Epoch 2 : [13536 / 40150] loss : 158.59768676757812, Batch time: 1.5038 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 : [14496 / 40150] loss : 140.0662384033203, Batch time: 1.4885 sec\n",
            "Epoch 2 : [15456 / 40150] loss : 224.93792724609375, Batch time: 1.4979 sec\n",
            "Epoch 2 : [16416 / 40150] loss : 159.01535034179688, Batch time: 1.4933 sec\n",
            "Epoch 2 : [17376 / 40150] loss : 179.4281463623047, Batch time: 1.4986 sec\n",
            "Epoch 2 : [18336 / 40150] loss : 149.22093200683594, Batch time: 1.4854 sec\n",
            "Epoch 2 : [19296 / 40150] loss : 168.46475219726562, Batch time: 1.5095 sec\n",
            "Epoch 2 : [20256 / 40150] loss : 172.0135955810547, Batch time: 1.5164 sec\n",
            "Epoch 2 : [21216 / 40150] loss : 157.4188690185547, Batch time: 1.5006 sec\n",
            "Epoch 2 : [22176 / 40150] loss : 119.13658142089844, Batch time: 1.5127 sec\n",
            "Epoch 2 : [23136 / 40150] loss : 152.80062866210938, Batch time: 1.5012 sec\n",
            "Epoch 2 : [24096 / 40150] loss : 137.72801208496094, Batch time: 1.4795 sec\n",
            "Epoch 2 : [25056 / 40150] loss : 172.39706420898438, Batch time: 1.5159 sec\n",
            "Epoch 2 : [26016 / 40150] loss : 167.52944946289062, Batch time: 1.5021 sec\n",
            "Epoch 2 : [26976 / 40150] loss : 156.11827087402344, Batch time: 1.4984 sec\n",
            "Epoch 2 : [27936 / 40150] loss : 175.4746551513672, Batch time: 1.4879 sec\n",
            "Epoch 2 : [28896 / 40150] loss : 154.560546875, Batch time: 1.5035 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 : [29856 / 40150] loss : 158.47955322265625, Batch time: 1.5150 sec\n",
            "Epoch 2 : [30816 / 40150] loss : 139.4441375732422, Batch time: 1.4958 sec\n",
            "Epoch 2 : [31776 / 40150] loss : 149.2689208984375, Batch time: 1.5091 sec\n",
            "Epoch 2 : [32736 / 40150] loss : 178.26145935058594, Batch time: 1.4972 sec\n",
            "Epoch 2 : [33696 / 40150] loss : 133.15911865234375, Batch time: 1.4979 sec\n",
            "Epoch 2 : [34656 / 40150] loss : 158.01324462890625, Batch time: 1.5026 sec\n",
            "Epoch 2 : [35616 / 40150] loss : 157.4577178955078, Batch time: 1.4802 sec\n",
            "Epoch 2 : [36576 / 40150] loss : 162.8234100341797, Batch time: 1.5115 sec\n",
            "Epoch 2 : [37536 / 40150] loss : 191.70547485351562, Batch time: 1.4976 sec\n",
            "Epoch 2 : [38496 / 40150] loss : 148.96774291992188, Batch time: 1.4973 sec\n",
            "Epoch 2 : [39456 / 40150] loss : 126.87998962402344, Batch time: 1.4953 sec\n",
            "Epoch 2 finished, Total Epoch time: 3487.7665 sec\n",
            "Epoch : 2, Loss : 158.58959261728072, Val_loss : 140.05805379039836\n",
            "Epoch 3 : [96 / 40150] loss : 165.5740966796875, Batch time: 1.5166 sec\n",
            "Epoch 3 : [1056 / 40150] loss : 116.83097839355469, Batch time: 1.5037 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 : [2016 / 40150] loss : 142.52377319335938, Batch time: 1.4959 sec\n",
            "Epoch 3 : [2976 / 40150] loss : 158.5430908203125, Batch time: 1.4874 sec\n",
            "Epoch 3 : [3936 / 40150] loss : 172.1672821044922, Batch time: 1.5102 sec\n",
            "Epoch 3 : [4896 / 40150] loss : 151.59371948242188, Batch time: 1.5004 sec\n",
            "Epoch 3 : [5856 / 40150] loss : 115.05216979980469, Batch time: 1.4866 sec\n",
            "Epoch 3 : [6816 / 40150] loss : 170.8779754638672, Batch time: 1.4885 sec\n",
            "Epoch 3 : [7776 / 40150] loss : 121.93003845214844, Batch time: 1.5002 sec\n",
            "Epoch 3 : [8736 / 40150] loss : 135.2753143310547, Batch time: 1.5144 sec\n",
            "Epoch 3 : [9696 / 40150] loss : 147.27899169921875, Batch time: 1.5061 sec\n",
            "Epoch 3 : [10656 / 40150] loss : 139.896484375, Batch time: 1.4925 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 : [11616 / 40150] loss : 174.83029174804688, Batch time: 1.5032 sec\n",
            "Epoch 3 : [12576 / 40150] loss : 127.37603759765625, Batch time: 1.4856 sec\n",
            "Epoch 3 : [13536 / 40150] loss : 120.6906967163086, Batch time: 1.4695 sec\n",
            "Epoch 3 : [14496 / 40150] loss : 159.74114990234375, Batch time: 1.5036 sec\n",
            "Epoch 3 : [15456 / 40150] loss : 188.3479461669922, Batch time: 1.4849 sec\n",
            "Epoch 3 : [16416 / 40150] loss : 134.13861083984375, Batch time: 1.4946 sec\n",
            "Epoch 3 : [17376 / 40150] loss : 107.93959045410156, Batch time: 1.5159 sec\n",
            "Epoch 3 : [18145 / 40150] loss : 153.8011474609375, Batch time: 1.2116 sec\n",
            "Epoch 3 : [19296 / 40150] loss : 187.0440673828125, Batch time: 1.5038 sec\n",
            "Epoch 3 : [20256 / 40150] loss : 127.5574951171875, Batch time: 1.5036 sec\n",
            "Epoch 3 : [21216 / 40150] loss : 155.30670166015625, Batch time: 1.4915 sec\n",
            "Epoch 3 : [22176 / 40150] loss : 154.28961181640625, Batch time: 1.4904 sec\n",
            "Epoch 3 : [23136 / 40150] loss : 125.8553466796875, Batch time: 1.4765 sec\n",
            "Epoch 3 : [24096 / 40150] loss : 146.396728515625, Batch time: 1.4836 sec\n",
            "Epoch 3 : [25056 / 40150] loss : 139.6400604248047, Batch time: 1.4774 sec\n",
            "Epoch 3 : [26016 / 40150] loss : 115.99411010742188, Batch time: 1.4875 sec\n",
            "Epoch 3 : [26976 / 40150] loss : 151.4711151123047, Batch time: 1.4879 sec\n",
            "Epoch 3 : [27936 / 40150] loss : 146.3050537109375, Batch time: 1.4736 sec\n",
            "Epoch 3 : [28896 / 40150] loss : 115.18992614746094, Batch time: 1.4931 sec\n",
            "Epoch 3 : [29856 / 40150] loss : 169.3997802734375, Batch time: 1.4933 sec\n",
            "Epoch 3 : [30816 / 40150] loss : 183.90264892578125, Batch time: 1.5050 sec\n",
            "Epoch 3 : [31776 / 40150] loss : 134.40989685058594, Batch time: 1.4959 sec\n",
            "Epoch 3 : [32736 / 40150] loss : 149.23037719726562, Batch time: 1.4699 sec\n",
            "Epoch 3 : [33696 / 40150] loss : 141.40988159179688, Batch time: 1.4843 sec\n",
            "Epoch 3 : [34656 / 40150] loss : 110.96183776855469, Batch time: 1.4717 sec\n",
            "Epoch 3 : [35616 / 40150] loss : 149.156494140625, Batch time: 1.4877 sec\n",
            "Epoch 3 : [36576 / 40150] loss : 144.64675903320312, Batch time: 1.4968 sec\n",
            "Epoch 3 : [37536 / 40150] loss : 192.9213104248047, Batch time: 1.4856 sec\n",
            "Epoch 3 : [38496 / 40150] loss : 155.77923583984375, Batch time: 1.4865 sec\n",
            "Epoch 3 : [39456 / 40150] loss : 160.7519989013672, Batch time: 1.4755 sec\n",
            "Epoch 3 finished, Total Epoch time: 3397.0818 sec\n",
            "Epoch : 3, Loss : 148.9369029771172, Val_loss : 134.6221329311155\n",
            "Epoch 4 : [96 / 40150] loss : 93.44366455078125, Batch time: 1.5112 sec\n",
            "Epoch 4 : [1056 / 40150] loss : 174.18075561523438, Batch time: 1.4850 sec\n",
            "Epoch 4 : [2016 / 40150] loss : 133.8297119140625, Batch time: 1.4949 sec\n",
            "Epoch 4 : [2976 / 40150] loss : 128.85142517089844, Batch time: 1.4726 sec\n",
            "Epoch 4 : [3936 / 40150] loss : 153.3150634765625, Batch time: 1.4661 sec\n",
            "Epoch 4 : [4896 / 40150] loss : 132.59365844726562, Batch time: 1.4867 sec\n",
            "Epoch 4 : [5856 / 40150] loss : 126.5703125, Batch time: 1.4980 sec\n",
            "Epoch 4 : [6816 / 40150] loss : 135.49794006347656, Batch time: 1.4876 sec\n",
            "Epoch 4 : [7776 / 40150] loss : 133.79693603515625, Batch time: 1.4799 sec\n",
            "Epoch 4 : [8736 / 40150] loss : 104.8772201538086, Batch time: 1.4901 sec\n",
            "Epoch 4 : [9696 / 40150] loss : 160.57533264160156, Batch time: 1.4719 sec\n",
            "Epoch 4 : [10656 / 40150] loss : 163.02696228027344, Batch time: 1.5024 sec\n",
            "Epoch 4 : [11616 / 40150] loss : 119.6645736694336, Batch time: 1.5054 sec\n",
            "Epoch 4 : [12576 / 40150] loss : 164.28704833984375, Batch time: 1.4711 sec\n",
            "Epoch 4 : [13536 / 40150] loss : 162.35336303710938, Batch time: 1.4836 sec\n",
            "Epoch 4 : [14496 / 40150] loss : 159.96630859375, Batch time: 1.4971 sec\n",
            "Epoch 4 : [15456 / 40150] loss : 148.89248657226562, Batch time: 1.4988 sec\n",
            "Epoch 4 : [16416 / 40150] loss : 132.12908935546875, Batch time: 1.5029 sec\n",
            "Epoch 4 : [17376 / 40150] loss : 129.3789520263672, Batch time: 1.4946 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 : [18336 / 40150] loss : 170.10484313964844, Batch time: 1.4866 sec\n",
            "Epoch 4 : [19296 / 40150] loss : 152.04833984375, Batch time: 1.4915 sec\n",
            "Epoch 4 : [20256 / 40150] loss : 178.55117797851562, Batch time: 1.4982 sec\n",
            "Epoch 4 : [21216 / 40150] loss : 141.45050048828125, Batch time: 1.4760 sec\n",
            "Epoch 4 : [22176 / 40150] loss : 161.58448791503906, Batch time: 1.4818 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 : [23136 / 40150] loss : 127.72850036621094, Batch time: 1.5084 sec\n",
            "Epoch 4 : [24096 / 40150] loss : 108.4115219116211, Batch time: 1.5010 sec\n",
            "Epoch 4 : [25056 / 40150] loss : 105.5582275390625, Batch time: 1.4978 sec\n",
            "Epoch 4 : [26016 / 40150] loss : 181.17747497558594, Batch time: 1.4951 sec\n",
            "Epoch 4 : [26976 / 40150] loss : 149.5812530517578, Batch time: 1.5042 sec\n",
            "Epoch 4 : [27936 / 40150] loss : 136.40036010742188, Batch time: 1.4971 sec\n",
            "Epoch 4 : [28896 / 40150] loss : 137.45068359375, Batch time: 1.4873 sec\n",
            "Epoch 4 : [29856 / 40150] loss : 122.8703842163086, Batch time: 1.5056 sec\n",
            "Epoch 4 : [30816 / 40150] loss : 159.84300231933594, Batch time: 1.4920 sec\n",
            "Epoch 4 : [31776 / 40150] loss : 138.0618896484375, Batch time: 1.4966 sec\n",
            "Epoch 4 : [32736 / 40150] loss : 167.87701416015625, Batch time: 1.4968 sec\n",
            "Epoch 4 : [33696 / 40150] loss : 153.8187255859375, Batch time: 1.5079 sec\n",
            "Epoch 4 : [34656 / 40150] loss : 162.6517333984375, Batch time: 1.5127 sec\n",
            "Epoch 4 : [35616 / 40150] loss : 133.95401000976562, Batch time: 1.5004 sec\n",
            "Epoch 4 : [36576 / 40150] loss : 121.7900619506836, Batch time: 1.5071 sec\n",
            "Epoch 4 : [37536 / 40150] loss : 156.70550537109375, Batch time: 1.4804 sec\n",
            "Epoch 4 : [38496 / 40150] loss : 130.92532348632812, Batch time: 1.5077 sec\n",
            "Epoch 4 : [39456 / 40150] loss : 173.0731201171875, Batch time: 1.4958 sec\n",
            "Epoch 4 finished, Total Epoch time: 3310.7062 sec\n",
            "Epoch : 4, Loss : 141.7470114805818, Val_loss : 132.08890734978442\n",
            "Epoch 5 : [96 / 40150] loss : 134.8874053955078, Batch time: 1.5178 sec\n",
            "Epoch 5 : [1056 / 40150] loss : 123.6131591796875, Batch time: 1.4887 sec\n",
            "Epoch 5 : [2016 / 40150] loss : 146.65350341796875, Batch time: 1.5148 sec\n",
            "Epoch 5 : [2976 / 40150] loss : 120.76152038574219, Batch time: 1.4779 sec\n",
            "Epoch 5 : [3936 / 40150] loss : 150.4748992919922, Batch time: 1.4977 sec\n",
            "Epoch 5 : [4896 / 40150] loss : 154.0732421875, Batch time: 1.5061 sec\n",
            "Epoch 5 : [5856 / 40150] loss : 117.28166198730469, Batch time: 1.4901 sec\n",
            "Epoch 5 : [6816 / 40150] loss : 171.9473114013672, Batch time: 1.5034 sec\n",
            "Epoch 5 : [7776 / 40150] loss : 114.3951416015625, Batch time: 1.4930 sec\n",
            "Epoch 5 : [8736 / 40150] loss : 161.8273468017578, Batch time: 1.4859 sec\n",
            "Epoch 5 : [9696 / 40150] loss : 131.4770050048828, Batch time: 1.4934 sec\n",
            "Epoch 5 : [10656 / 40150] loss : 134.23484802246094, Batch time: 1.5146 sec\n",
            "Epoch 5 : [11616 / 40150] loss : 163.98968505859375, Batch time: 1.5038 sec\n",
            "Epoch 5 : [12576 / 40150] loss : 152.97842407226562, Batch time: 1.4871 sec\n",
            "Epoch 5 : [13536 / 40150] loss : 106.08030700683594, Batch time: 1.4895 sec\n",
            "Epoch 5 : [14496 / 40150] loss : 120.14470672607422, Batch time: 1.4907 sec\n",
            "Epoch 5 : [15456 / 40150] loss : 102.21664428710938, Batch time: 1.4883 sec\n",
            "Epoch 5 : [16416 / 40150] loss : 122.2994384765625, Batch time: 1.5077 sec\n",
            "Epoch 5 : [17376 / 40150] loss : 117.02842712402344, Batch time: 1.4922 sec\n",
            "Epoch 5 : [18336 / 40150] loss : 159.95448303222656, Batch time: 1.5026 sec\n",
            "Epoch 5 : [19296 / 40150] loss : 144.55284118652344, Batch time: 1.4924 sec\n",
            "Epoch 5 : [20256 / 40150] loss : 128.54991149902344, Batch time: 1.4972 sec\n",
            "Epoch 5 : [21216 / 40150] loss : 156.15628051757812, Batch time: 1.4970 sec\n",
            "Epoch 5 : [22176 / 40150] loss : 124.4836654663086, Batch time: 1.4745 sec\n",
            "Epoch 5 : [23136 / 40150] loss : 153.1558074951172, Batch time: 1.4748 sec\n",
            "Epoch 5 : [24096 / 40150] loss : 158.6188201904297, Batch time: 1.5106 sec\n",
            "Epoch 5 : [25056 / 40150] loss : 135.31790161132812, Batch time: 1.5048 sec\n",
            "Epoch 5 : [26016 / 40150] loss : 115.5987777709961, Batch time: 1.5126 sec\n",
            "Epoch 5 : [26976 / 40150] loss : 117.06253051757812, Batch time: 1.5112 sec\n",
            "Epoch 5 : [27936 / 40150] loss : 174.83035278320312, Batch time: 1.5069 sec\n",
            "Epoch 5 : [28896 / 40150] loss : 135.4016571044922, Batch time: 1.4931 sec\n",
            "Epoch 5 : [29856 / 40150] loss : 140.71014404296875, Batch time: 1.4959 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 : [30816 / 40150] loss : 116.83993530273438, Batch time: 1.5093 sec\n",
            "Epoch 5 : [31776 / 40150] loss : 111.31179809570312, Batch time: 1.4960 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 : [32736 / 40150] loss : 148.14990234375, Batch time: 1.4999 sec\n",
            "Epoch 5 : [33696 / 40150] loss : 123.16380310058594, Batch time: 1.4957 sec\n",
            "Epoch 5 : [34656 / 40150] loss : 119.87406921386719, Batch time: 1.5113 sec\n",
            "Epoch 5 : [35616 / 40150] loss : 107.93733978271484, Batch time: 1.5061 sec\n",
            "Epoch 5 : [36576 / 40150] loss : 127.38145446777344, Batch time: 1.4774 sec\n",
            "Epoch 5 : [37536 / 40150] loss : 97.5975341796875, Batch time: 1.4964 sec\n",
            "Epoch 5 : [38496 / 40150] loss : 100.09808349609375, Batch time: 1.5011 sec\n",
            "Epoch 5 : [39456 / 40150] loss : 135.4002685546875, Batch time: 1.5096 sec\n",
            "Epoch 5 finished, Total Epoch time: 3321.1722 sec\n",
            "Epoch : 5, Loss : 136.13610421046437, Val_loss : 124.25044768711307\n",
            "Epoch 6 : [96 / 40150] loss : 133.3868408203125, Batch time: 1.5042 sec\n",
            "Epoch 6 : [1056 / 40150] loss : 110.22212982177734, Batch time: 1.4921 sec\n",
            "Epoch 6 : [2016 / 40150] loss : 150.79043579101562, Batch time: 1.5085 sec\n",
            "Epoch 6 : [2976 / 40150] loss : 113.09274291992188, Batch time: 1.5158 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 : [3936 / 40150] loss : 170.88584899902344, Batch time: 1.4707 sec\n",
            "Epoch 6 : [4896 / 40150] loss : 111.3719482421875, Batch time: 1.5032 sec\n",
            "Epoch 6 : [5856 / 40150] loss : 97.89591979980469, Batch time: 1.4959 sec\n",
            "Epoch 6 : [6816 / 40150] loss : 128.2555389404297, Batch time: 1.4933 sec\n",
            "Epoch 6 : [7776 / 40150] loss : 112.336669921875, Batch time: 1.4923 sec\n",
            "Epoch 6 : [8736 / 40150] loss : 140.30694580078125, Batch time: 1.5205 sec\n",
            "Epoch 6 : [9696 / 40150] loss : 135.0364990234375, Batch time: 1.4886 sec\n",
            "Epoch 6 : [10656 / 40150] loss : 146.14891052246094, Batch time: 1.4846 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 : [11616 / 40150] loss : 152.44442749023438, Batch time: 1.4794 sec\n",
            "Epoch 6 : [12576 / 40150] loss : 119.0074691772461, Batch time: 1.5035 sec\n",
            "Epoch 6 : [13536 / 40150] loss : 118.15089416503906, Batch time: 1.4782 sec\n",
            "Epoch 6 : [14496 / 40150] loss : 128.25062561035156, Batch time: 1.4964 sec\n",
            "Epoch 6 : [15456 / 40150] loss : 125.86541748046875, Batch time: 1.4776 sec\n",
            "Epoch 6 : [16416 / 40150] loss : 111.12800598144531, Batch time: 1.5042 sec\n",
            "Epoch 6 : [17376 / 40150] loss : 129.53817749023438, Batch time: 1.4832 sec\n",
            "Epoch 6 : [18145 / 40150] loss : 111.55670928955078, Batch time: 1.2015 sec\n",
            "Epoch 6 : [19296 / 40150] loss : 161.306396484375, Batch time: 1.4696 sec\n",
            "Epoch 6 : [20256 / 40150] loss : 112.29794311523438, Batch time: 1.5019 sec\n",
            "Epoch 6 : [21216 / 40150] loss : 124.41532897949219, Batch time: 1.4926 sec\n",
            "Epoch 6 : [22176 / 40150] loss : 163.0113067626953, Batch time: 1.4869 sec\n",
            "Epoch 6 : [23136 / 40150] loss : 153.73968505859375, Batch time: 1.4890 sec\n",
            "Epoch 6 : [24096 / 40150] loss : 111.9295883178711, Batch time: 1.4903 sec\n",
            "Epoch 6 : [25056 / 40150] loss : 111.94149017333984, Batch time: 1.4806 sec\n",
            "Epoch 6 : [26016 / 40150] loss : 123.47779846191406, Batch time: 1.4959 sec\n",
            "Epoch 6 : [26976 / 40150] loss : 121.49447631835938, Batch time: 1.5005 sec\n",
            "Epoch 6 : [27936 / 40150] loss : 125.84684753417969, Batch time: 1.4873 sec\n",
            "Epoch 6 : [28896 / 40150] loss : 99.73171997070312, Batch time: 1.5029 sec\n",
            "Epoch 6 : [29856 / 40150] loss : 120.37236022949219, Batch time: 1.4897 sec\n",
            "Epoch 6 : [30816 / 40150] loss : 97.9851303100586, Batch time: 1.4728 sec\n",
            "Epoch 6 : [31776 / 40150] loss : 128.17831420898438, Batch time: 1.4966 sec\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-33e445748da2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mage_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_loop_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mage_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5763b9d00070>\u001b[0m in \u001b[0;36mtrain_loop_age\u001b[0;34m(dataloader, model, loss_fn, optimizer, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 에포크 시작 시간\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 배치 처리 시작 시간\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age_past'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Epoch 1 finished, Total Epoch time: 3335.0356 sec\n",
        "- Epoch : 1, Loss : 212.2974793245229, Val_loss : 154.38576752284789\n",
        "- Epoch 2 finished, Total Epoch time: 3487.7665 sec\n",
        "- Epoch : 2, Loss : 158.58959261728072, Val_loss : 140.05805379039836\n",
        "- Epoch 3 finished, Total Epoch time: 3397.0818 sec\n",
        "- Epoch : 3, Loss : 148.9369029771172, Val_loss : 134.6221329311155\n",
        "- Epoch 4 finished, Total Epoch time: 3310.7062 sec\n",
        "- Epoch : 4, Loss : 141.7470114805818, Val_loss : 132.08890734978442\n",
        "- Epoch 5 finished, Total Epoch time: 3321.1722 sec\n",
        "- Epoch : 5, Loss : 136.13610421046437, Val_loss : 124.25044768711307"
      ],
      "metadata": {
        "id": "DWfszBO8OBKI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NETtM2dfOC_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}