{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQCXYegJuf8n",
        "outputId": "89cfd968-a974-44cf-dc5e-ea8a39738551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m4JeK62MzmhT"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import subprocess\n",
        "import os\n",
        "# import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torchsummary\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageFile\n",
        "import json\n",
        "# import cv2\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import random\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "q3Aej2u0R-aR"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed=42):\n",
        "    \"\"\"\n",
        "    모든 랜덤 시드를 주어진 값으로 고정합니다.\n",
        "    \"\"\"\n",
        "    random.seed(seed)  # Python random 모듈\n",
        "    np.random.seed(seed)  # Numpy 랜덤 시드\n",
        "    torch.manual_seed(seed)  # PyTorch 랜덤 시드\n",
        "    torch.cuda.manual_seed(seed)  # GPU를 위한 PyTorch 랜덤 시드\n",
        "    torch.cuda.manual_seed_all(seed)  # 멀티 GPU를 위한 PyTorch 랜덤 시드\n",
        "\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LqLZA6YqaVI1"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_zip_paths, label_zip_paths, cache_dir, transform=None, workers=4):\n",
        "        super().__init__()\n",
        "        self.image_zip_paths = image_zip_paths\n",
        "        self.label_zip_paths = label_zip_paths\n",
        "        self.cache_dir = cache_dir\n",
        "        self.transform = transform\n",
        "        self.workers = workers\n",
        "\n",
        "        if not os.path.exists(self.cache_dir):\n",
        "            os.makedirs(self.cache_dir, exist_ok=True)\n",
        "\n",
        "        self.image_names = {}\n",
        "        self.label_names = {}\n",
        "        self.image_list = []\n",
        "\n",
        "        self._prepare()\n",
        "\n",
        "    def _extract_and_cache(self, zip_path, file_name, cache_file_path, attempts=3):\n",
        "        if os.path.exists(cache_file_path):\n",
        "            return True\n",
        "\n",
        "        command = [\"unzip\", \"-o\", zip_path, file_name, \"-d\", os.path.dirname(cache_file_path)]\n",
        "\n",
        "        for attempt in range(attempts):\n",
        "            result = subprocess.run(command, check=False, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            # 성공적으로 압축 해제되었거나, 경고만 있는 경우\n",
        "            if result.returncode == 0 or \"warning\" in result.stderr.decode().lower():\n",
        "                return True\n",
        "            else:\n",
        "                # 오류 메시지가 있고, 재시도 횟수가 남아있는 경우\n",
        "                print(f\"Attempt {attempt + 1}: Error unzipping file => {zip_path}\")\n",
        "                time.sleep(2 ** attempt)\n",
        "\n",
        "        # 모든 시도가 실패한 경우\n",
        "        print(f\"Failed to extract {file_name}\")\n",
        "        return False\n",
        "\n",
        "    def _prepare(self):\n",
        "        max_tries = 3\n",
        "        wait_seconds = 10\n",
        "\n",
        "        # 각 zip 파일에 대한 재시도 횟수를 추적\n",
        "        retries = {zip_path: 0 for zip_path in self.image_zip_paths + self.label_zip_paths}\n",
        "\n",
        "        # 전체 압축 파일 리스트\n",
        "        to_process = [(zip_path, '.png') for zip_path in self.image_zip_paths] + [(zip_path, '.json') for zip_path in self.label_zip_paths]\n",
        "\n",
        "        while to_process:\n",
        "            # 병렬처리\n",
        "            with ThreadPoolExecutor(max_workers=self.workers) as executor:\n",
        "                future_to_zip_path = {\n",
        "                    executor.submit(self._process_zip, zip_path, file_extension): (zip_path, file_extension)\n",
        "                    for zip_path, file_extension in to_process\n",
        "                }\n",
        "\n",
        "                # 처리 중 예외 발생 시 재시도할 작업 목록\n",
        "                to_retry = []\n",
        "\n",
        "                # future 객체의 작업완료 상황을 모니터링\n",
        "                for future in as_completed(future_to_zip_path):\n",
        "                    zip_path, file_extension = future_to_zip_path[future]\n",
        "\n",
        "                    try:\n",
        "                        success = future.result()\n",
        "                        if not success:\n",
        "                            raise Exception(f\"Failed to process {zip_path}\")\n",
        "\n",
        "                    except OSError as e: # 구글드라이브와의 연결로 인한 예외처리\n",
        "                        if e.errno == 107 and retries[zip_path] < max_tries:\n",
        "                            print(f\"OSError [Errno 107] => {zip_path}\")\n",
        "                            to_retry.append((zip_path, file_extension))\n",
        "                            retries[zip_path] += 1\n",
        "                            time.sleep(wait_seconds)  # 각 재시도 사이에 대기\n",
        "                            wait_seconds *= 2  # 대기 시간 증가\n",
        "                        else:\n",
        "                            print(f\"Unexpected Error : {zip_path}: {e}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Exception processing {zip_path}: {e}\")\n",
        "\n",
        "                # 재시도할 작업이 있으면 to_process 업데이트\n",
        "                to_process = to_retry if to_retry else []\n",
        "\n",
        "        self.image_list = sorted(self.image_names.keys())\n",
        "\n",
        "    def _process_zip(self, zip_path, file_extension):\n",
        "        success = True\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "\n",
        "            for file_name in sorted(zip_ref.namelist()):\n",
        "\n",
        "                if file_name.endswith(file_extension):\n",
        "                    base_name = os.path.splitext(os.path.basename(file_name))[0].lstrip('_')  # 확장자 제외 파일 기본 이름\n",
        "\n",
        "                    # 데이터 접근시 사용할 경로\n",
        "                    cache_file_path = os.path.join(self.cache_dir, os.path.basename(zip_path).replace('.zip', ''), file_name.replace('/', '_').lstrip('_'))\n",
        "\n",
        "                    if file_extension == '.png':\n",
        "                        self.image_names[base_name.lower()] = cache_file_path\n",
        "                    else:\n",
        "                        self.label_names[base_name.lower()] = cache_file_path\n",
        "\n",
        "                    extract_success = self._extract_and_cache(zip_path, file_name, cache_file_path)\n",
        "                    success = success and extract_success\n",
        "\n",
        "        return success\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 파일 이름을 키 리스트에서 추출\n",
        "        base_name = self.image_list[idx]\n",
        "\n",
        "        image_path = self.image_names.get(base_name)\n",
        "\n",
        "        try:\n",
        "            image = Image.open(image_path)\n",
        "        except Exception as e:\n",
        "            return None\n",
        "\n",
        "        label_path = self.label_names.get(base_name)\n",
        "        with open(label_path, 'r') as f:\n",
        "            label_data = json.load(f)\n",
        "\n",
        "        age_past = label_data['age_past']\n",
        "        gender = label_data['gender']\n",
        "        box = label_data['annotation'][0]['box']\n",
        "\n",
        "        image = image.crop((box['x'], box['y'], box['x'] + box['w'], box['y'] + box['h']))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        gender_label = 0 if gender == 'male' else 1\n",
        "\n",
        "        label = {'age_past': age_past, 'gender': gender_label}\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dvBmQ0JM9Hmd"
      },
      "outputs": [],
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomRotation(5),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TSmpmi_f2sVh"
      },
      "outputs": [],
      "source": [
        "def get_zip_files(directory):\n",
        "    return [os.path.join(directory, zip) for zip in os.listdir(directory) if zip.endswith('.zip')] # 리스트를 정렬하면 속도 하락\n",
        "\n",
        "train_images = '/content/drive/Othercomputers/Home/data_age/data/Training/image'\n",
        "train_labels = '/content/drive/Othercomputers/Home/data_age/data/Training/label'\n",
        "train_cache = '/content/cache/train'\n",
        "\n",
        "val_images = '/content/drive/Othercomputers/Home/data_age/data/Validation/image'\n",
        "val_labels = '/content/drive/Othercomputers/Home/data_age/data/Validation/label'\n",
        "val_cache = '/content/cache/val'\n",
        "\n",
        "train_image_zips = get_zip_files(train_images)\n",
        "train_label_zips = get_zip_files(train_labels)\n",
        "val_image_zips = get_zip_files(val_images)\n",
        "val_label_zips = get_zip_files(val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5sh35etoByU",
        "outputId": "3c0225ae-2022-41e0-a297-56dcdaa9e232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempt 1: Error unzipping file => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0301.zipAttempt 1: Error unzipping file => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0015.zip\n",
            "Attempt 1: Error unzipping file => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0584.zip\n",
            "\n",
            "Attempt 1: Error unzipping file => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0480.zip\n",
            "Attempt 2: Error unzipping file => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0015.zip\n",
            "Attempt 2: Error unzipping file => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0584.zip\n",
            "Attempt 2: Error unzipping file => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0301.zip\n",
            "Attempt 2: Error unzipping file => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0480.zip\n",
            "OSError [Errno 107] => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0015.zip\n",
            "OSError [Errno 107] => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0301.zip\n",
            "OSError [Errno 107] => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0584.zip\n",
            "OSError [Errno 107] => /content/drive/Othercomputers/Home/data_age/data/Training/image/TS_0480.zip\n",
            "CPU times: user 46 s, sys: 20.4 s, total: 1min 6s\n",
            "Wall time: 41min 38s\n"
          ]
        }
      ],
      "source": [
        "%time train_dataset = CustomDataset(train_image_zips, train_label_zips, train_cache, transform_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBrea_zXmnqD",
        "outputId": "556be8e4-1c35-47e4-df19-c86e1eb8ccb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 5.55 s, sys: 2.4 s, total: 7.95 s\n",
            "Wall time: 4min 34s\n"
          ]
        }
      ],
      "source": [
        "%time val_dataset = CustomDataset(val_image_zips, val_label_zips, val_cache, transform_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wjSTv5TojZtu"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(batch):\n",
        "    batch = [item for item in batch if item is not None]\n",
        "    return torch.utils.data.dataloader.default_collate(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "BXNcznsi9-yA"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=4\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2,\n",
        "    prefetch_factor=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC0xKBBb-Rbj",
        "outputId": "e84b0e52-ff7e-4d01-c194-8bbafddf6f17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 3, 224, 224])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x, y = next(iter(train_loader))\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJSln4Ba-rKT",
        "outputId": "6bed7688-3a01-4fbc-b302-4d01c8083f62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([64]), torch.Size([64]))"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y['age_past'].shape, y['gender'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3wCDUbTQ9OF",
        "outputId": "544db91f-5fe2-48e8-ecb6-20983a408355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "e14N42FPDUA6"
      },
      "outputs": [],
      "source": [
        "class Age_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1_1 = nn.Conv2d(3, 128, kernel_size=3, padding='same')\n",
        "        self.conv1_2 = nn.Conv2d(128, 128, kernel_size=3, padding='same')\n",
        "        self.conv1_3 = nn.Conv2d(128, 128, kernel_size=3, padding='same')\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.one_conv1 = nn.Conv2d(128, 64, kernel_size=1)\n",
        "        self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
        "        self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding='same')\n",
        "        self.conv2_3 = nn.Conv2d(128, 128, kernel_size=3, padding='same')\n",
        "\n",
        "        self.one_conv2 = nn.Conv2d(128, 64, kernel_size=1)\n",
        "        self.conv3_1 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
        "        self.conv3_2 = nn.Conv2d(128, 256, kernel_size=3, padding='same')\n",
        "        self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding='same')\n",
        "\n",
        "        self.one_conv3 = nn.Conv2d(256, 64, kernel_size=1)\n",
        "        self.conv4_1 = nn.Conv2d(64, 128, kernel_size=3, padding='same')\n",
        "        self.conv4_2 = nn.Conv2d(128, 256, kernel_size=3, padding='same')\n",
        "        self.conv4_3 = nn.Conv2d(256, 512, kernel_size=3, padding='same')\n",
        "        self.one_conv4 = nn.Conv2d(512, 128, kernel_size=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(25088, 128)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1_1(x))\n",
        "        x = F.relu(self.conv1_2(x))\n",
        "        x = F.relu(self.conv1_3(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.one_conv1(x))\n",
        "        x = F.relu(self.conv2_1(x))\n",
        "        x = F.relu(self.conv2_2(x))\n",
        "        x = F.relu(self.conv2_3(x))\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = F.relu(self.one_conv2(x))\n",
        "        x = F.relu(self.conv3_1(x))\n",
        "        x = F.relu(self.conv3_2(x))\n",
        "        x = F.relu(self.conv3_3(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.one_conv3(x))\n",
        "        x = F.relu(self.conv4_1(x))\n",
        "        x = F.relu(self.conv4_2(x))\n",
        "        x = F.relu(self.conv4_3(x))\n",
        "        x = F.relu(self.one_conv4(x))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(self.dropout(x)))\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x).squeeze()\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "t0rJc-tqHzfS"
      },
      "outputs": [],
      "source": [
        "class Gender_Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 36, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(36, 64, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3)\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(512 * 4 * 4, 512)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "        self.fc2 = nn.Linear(512, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = self.pool(F.relu(self.conv4(x)))\n",
        "        x = self.pool(F.relu(self.conv5(x)))\n",
        "\n",
        "        x = x.view(-1, 512 * 4 * 4)\n",
        "        x = F.relu(self.fc1(self.dropout(x)))\n",
        "        x = self.fc2(x)\n",
        "        x = x.squeeze()\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42OyTCgWLQ93",
        "outputId": "aba1dd39-0198-4c53-c220-4bc7d608bbe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1        [-1, 128, 224, 224]           3,584\n",
            "            Conv2d-2        [-1, 128, 224, 224]         147,584\n",
            "            Conv2d-3        [-1, 128, 224, 224]         147,584\n",
            "         MaxPool2d-4        [-1, 128, 112, 112]               0\n",
            "            Conv2d-5         [-1, 64, 112, 112]           8,256\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "            Conv2d-7        [-1, 128, 112, 112]         147,584\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "         MaxPool2d-9          [-1, 128, 56, 56]               0\n",
            "           Conv2d-10           [-1, 64, 56, 56]           8,256\n",
            "           Conv2d-11          [-1, 128, 56, 56]          73,856\n",
            "           Conv2d-12          [-1, 256, 56, 56]         295,168\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "        MaxPool2d-14          [-1, 256, 28, 28]               0\n",
            "           Conv2d-15           [-1, 64, 28, 28]          16,448\n",
            "           Conv2d-16          [-1, 128, 28, 28]          73,856\n",
            "           Conv2d-17          [-1, 256, 28, 28]         295,168\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "           Conv2d-19          [-1, 128, 28, 28]          65,664\n",
            "        MaxPool2d-20          [-1, 128, 14, 14]               0\n",
            "          Dropout-21                [-1, 25088]               0\n",
            "           Linear-22                  [-1, 128]       3,211,392\n",
            "           Linear-23                    [-1, 1]             129\n",
            "================================================================\n",
            "Total params: 6,486,209\n",
            "Trainable params: 6,486,209\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 230.45\n",
            "Params size (MB): 24.74\n",
            "Estimated Total Size (MB): 255.77\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "age_model = Age_Net().to(device)\n",
        "torchsummary.summary(age_model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19.79898987322333"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "50176 / 128\n",
        "np.sqrt(392)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6bsFnItMeAs",
        "outputId": "94eeb8c1-5643-459a-c3d4-b6ff8b9daad3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 36, 222, 222]           1,008\n",
            "         MaxPool2d-2         [-1, 36, 110, 110]               0\n",
            "            Conv2d-3         [-1, 64, 108, 108]          20,800\n",
            "         MaxPool2d-4           [-1, 64, 53, 53]               0\n",
            "            Conv2d-5          [-1, 128, 51, 51]          73,856\n",
            "         MaxPool2d-6          [-1, 128, 25, 25]               0\n",
            "            Conv2d-7          [-1, 256, 23, 23]         295,168\n",
            "         MaxPool2d-8          [-1, 256, 11, 11]               0\n",
            "            Conv2d-9            [-1, 512, 9, 9]       1,180,160\n",
            "        MaxPool2d-10            [-1, 512, 4, 4]               0\n",
            "          Dropout-11                 [-1, 8192]               0\n",
            "           Linear-12                  [-1, 512]       4,194,816\n",
            "           Linear-13                    [-1, 1]             513\n",
            "================================================================\n",
            "Total params: 5,766,321\n",
            "Trainable params: 5,766,321\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 28.79\n",
            "Params size (MB): 22.00\n",
            "Estimated Total Size (MB): 51.36\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "gender_model = Gender_Net().to(device)\n",
        "torchsummary.summary(gender_model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ujNm-g_RO3r0"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.optim as optim\n",
        "\n",
        "opt_age = optim.Adam(age_model.parameters(), lr=0.0003)\n",
        "age_lr_scheduler = ReduceLROnPlateau(opt_age, mode='min', verbose=True)\n",
        "\n",
        "opt_gender = optim.Adam(gender_model.parameters(), lr=0.0003)\n",
        "gender_lr_scheduler = ReduceLROnPlateau(opt_gender, mode='min', verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Hx8_usRMTCus"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=5, verbose=False, delta=0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.best_loss = np.inf\n",
        "        self.early_stop = False\n",
        "        self.counter = 0\n",
        "\n",
        "    def __call__(self, val_loss):\n",
        "        if self.best_loss - val_loss > self.delta:\n",
        "            self.best_loss = val_loss\n",
        "            self.counter = 0\n",
        "        else:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "                if self.verbose:\n",
        "                    print(\"Early stopping\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ndXBKj_zTTVB"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(patience=5, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rWMH8jaiQZ_6"
      },
      "outputs": [],
      "source": [
        "def train_loop_age(dataloader, model, loss_fn, optimizer, epoch):\n",
        "    model.train()\n",
        "    size = len(dataloader.dataset)\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()  # 에포크 시작 시간\n",
        "\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        batch_start_time = time.time()  # 배치 처리 시작 시간\n",
        "        x, y = x.to(device), y['age_past'].float().to(device)\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred.squeeze(), y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_process_time = time.time() - batch_start_time\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            processed = (batch + 1) * len(x)\n",
        "            print(f'Epoch {epoch+1} : [{processed} / {size}] loss : {loss.item()}, Batch time: {batch_process_time:.4f} sec')\n",
        "\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch+1} finished, Total Epoch time: {epoch_time:.4f} sec\")\n",
        "    return average_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QLUS456MTlUU"
      },
      "outputs": [],
      "source": [
        "def validation_loop_age(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y['age_past'].float().to(device)\n",
        "            pred = model(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(dataloader)\n",
        "    return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7DU8WjVus4Iw"
      },
      "outputs": [],
      "source": [
        "def save_model(epoch, model, optimizer, path):\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WCj-n1ApThX7"
      },
      "outputs": [],
      "source": [
        "# start = time.time()\n",
        "# for epoch in range(30):\n",
        "#     age_loss = train_loop_age(train_loader, age_model, nn.MSELoss(), opt_age, epoch)\n",
        "#     val_loss = validation_loop_age(val_loader, age_model, nn.MSELoss(), device)\n",
        "#     age_lr_scheduler.step(val_loss)\n",
        "\n",
        "#     early_stopping(val_loss)\n",
        "#     if early_stopping.early_stop:\n",
        "#         print(\"Early stopping triggered\")\n",
        "#         save_model(epoch, age_model, opt_age, '/content/drive/MyDrive/DL_DATA/Model/Cashe/age_model_checkpoint.pth')\n",
        "#         break\n",
        "\n",
        "#     save_model(epoch, age_model, opt_age, f'/content/drive/MyDrive/DL_DATA/Model/Cashe/age_model_checkpoint_epoch_{epoch+1}.pth')\n",
        "#     print(f'Epoch : {epoch+1}, Loss : {age_loss}, Val_loss : {val_loss}')\n",
        "\n",
        "# total_time = time.time() - start\n",
        "# # 전체 학습 시간 출력\n",
        "# hours, rem = divmod(total_time, 3600)\n",
        "# minutes, seconds = divmod(rem, 60)\n",
        "# print(\"Total training time: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "kHEuSHa4nG19"
      },
      "outputs": [],
      "source": [
        "# age 모델 이어서 학습\n",
        "def load_model(model, optimizer, path):\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    return model, optimizer, epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YrgqihhJTwfA",
        "outputId": "ecfa349c-e2cc-4aa0-ea3d-49d92d8d9101"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 : [64 / 40150] loss : 49.313148498535156, Batch time: 3.2401 sec\n",
            "Epoch 12 : [704 / 40150] loss : 32.76795196533203, Batch time: 1.7047 sec\n",
            "Epoch 12 : [1344 / 40150] loss : 29.350566864013672, Batch time: 1.7053 sec\n",
            "Epoch 12 : [1984 / 40150] loss : 35.77113723754883, Batch time: 1.6939 sec\n",
            "Epoch 12 : [2624 / 40150] loss : 25.802255630493164, Batch time: 1.8060 sec\n",
            "Epoch 12 : [3264 / 40150] loss : 29.548646926879883, Batch time: 1.8062 sec\n",
            "Epoch 12 : [3904 / 40150] loss : 39.687034606933594, Batch time: 1.8207 sec\n",
            "Epoch 12 : [4544 / 40150] loss : 24.013076782226562, Batch time: 1.8464 sec\n",
            "Epoch 12 : [5184 / 40150] loss : 18.948627471923828, Batch time: 1.7831 sec\n",
            "Epoch 12 : [5824 / 40150] loss : 26.584285736083984, Batch time: 1.8123 sec\n",
            "Epoch 12 : [6464 / 40150] loss : 37.56182861328125, Batch time: 1.8067 sec\n",
            "Epoch 12 : [7104 / 40150] loss : 35.59412384033203, Batch time: 1.8399 sec\n",
            "Epoch 12 : [7744 / 40150] loss : 39.27695083618164, Batch time: 1.8276 sec\n",
            "Epoch 12 : [8384 / 40150] loss : 44.827125549316406, Batch time: 1.8267 sec\n",
            "Epoch 12 : [9024 / 40150] loss : 32.20201873779297, Batch time: 1.7982 sec\n",
            "Epoch 12 : [9664 / 40150] loss : 28.664512634277344, Batch time: 1.8172 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 : [10304 / 40150] loss : 40.217262268066406, Batch time: 1.8048 sec\n",
            "Epoch 12 : [10944 / 40150] loss : 18.308425903320312, Batch time: 1.8371 sec\n",
            "Epoch 12 : [11584 / 40150] loss : 37.61986541748047, Batch time: 1.8410 sec\n",
            "Epoch 12 : [12224 / 40150] loss : 33.50717544555664, Batch time: 1.8225 sec\n",
            "Epoch 12 : [12864 / 40150] loss : 31.02480125427246, Batch time: 1.8345 sec\n",
            "Epoch 12 : [13504 / 40150] loss : 27.472766876220703, Batch time: 1.8199 sec\n",
            "Epoch 12 : [14144 / 40150] loss : 38.95669937133789, Batch time: 1.8177 sec\n",
            "Epoch 12 : [14784 / 40150] loss : 46.026344299316406, Batch time: 1.8363 sec\n",
            "Epoch 12 : [15424 / 40150] loss : 40.643348693847656, Batch time: 1.8505 sec\n",
            "Epoch 12 : [16064 / 40150] loss : 50.301918029785156, Batch time: 1.8402 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 : [16704 / 40150] loss : 29.849184036254883, Batch time: 1.8474 sec\n",
            "Epoch 12 : [17344 / 40150] loss : 28.641448974609375, Batch time: 1.8435 sec\n",
            "Epoch 12 : [17984 / 40150] loss : 37.5587158203125, Batch time: 1.7993 sec\n",
            "Epoch 12 : [18624 / 40150] loss : 49.304649353027344, Batch time: 1.8356 sec\n",
            "Epoch 12 : [19264 / 40150] loss : 39.83075714111328, Batch time: 1.8409 sec\n",
            "Epoch 12 : [19904 / 40150] loss : 36.525779724121094, Batch time: 1.8192 sec\n",
            "Epoch 12 : [20544 / 40150] loss : 25.27975082397461, Batch time: 1.8117 sec\n",
            "Epoch 12 : [21184 / 40150] loss : 36.42578887939453, Batch time: 1.8074 sec\n",
            "Epoch 12 : [21824 / 40150] loss : 18.983585357666016, Batch time: 1.7873 sec\n",
            "Epoch 12 : [22464 / 40150] loss : 28.57994842529297, Batch time: 1.8159 sec\n",
            "Epoch 12 : [23104 / 40150] loss : 29.65227508544922, Batch time: 1.8260 sec\n",
            "Epoch 12 : [23744 / 40150] loss : 29.826427459716797, Batch time: 1.8204 sec\n",
            "Epoch 12 : [24384 / 40150] loss : 25.215641021728516, Batch time: 1.8087 sec\n",
            "Epoch 12 : [25024 / 40150] loss : 30.581052780151367, Batch time: 1.8356 sec\n",
            "Epoch 12 : [25664 / 40150] loss : 29.861194610595703, Batch time: 1.8328 sec\n",
            "Epoch 12 : [26304 / 40150] loss : 31.90984344482422, Batch time: 1.8415 sec\n",
            "Epoch 12 : [26944 / 40150] loss : 49.1702995300293, Batch time: 1.8104 sec\n",
            "Epoch 12 : [27584 / 40150] loss : 35.09059143066406, Batch time: 1.8201 sec\n",
            "Epoch 12 : [28224 / 40150] loss : 50.89997863769531, Batch time: 1.8343 sec\n",
            "Epoch 12 : [28864 / 40150] loss : 35.690696716308594, Batch time: 1.8278 sec\n",
            "Epoch 12 : [29504 / 40150] loss : 32.09653091430664, Batch time: 1.8563 sec\n",
            "Epoch 12 : [30144 / 40150] loss : 30.092220306396484, Batch time: 1.8126 sec\n",
            "Epoch 12 : [30784 / 40150] loss : 31.81711196899414, Batch time: 1.8374 sec\n",
            "Epoch 12 : [31424 / 40150] loss : 36.227699279785156, Batch time: 1.8301 sec\n",
            "Epoch 12 : [32064 / 40150] loss : 34.521209716796875, Batch time: 1.8314 sec\n",
            "Epoch 12 : [32704 / 40150] loss : 31.50055503845215, Batch time: 1.8501 sec\n",
            "Epoch 12 : [33344 / 40150] loss : 33.87825393676758, Batch time: 1.8343 sec\n",
            "Epoch 12 : [33984 / 40150] loss : 24.04047203063965, Batch time: 1.8558 sec\n",
            "Epoch 12 : [34624 / 40150] loss : 32.37480926513672, Batch time: 1.8359 sec\n",
            "Epoch 12 : [35264 / 40150] loss : 22.931529998779297, Batch time: 1.8068 sec\n",
            "Epoch 12 : [35904 / 40150] loss : 34.361106872558594, Batch time: 1.7660 sec\n",
            "Epoch 12 : [36544 / 40150] loss : 33.59540557861328, Batch time: 1.7817 sec\n",
            "Epoch 12 : [37184 / 40150] loss : 27.592365264892578, Batch time: 1.7750 sec\n",
            "Epoch 12 : [37233 / 40150] loss : 44.41810989379883, Batch time: 2.0710 sec\n",
            "Epoch 12 : [38464 / 40150] loss : 54.31675338745117, Batch time: 1.7619 sec\n",
            "Epoch 12 : [39104 / 40150] loss : 33.031463623046875, Batch time: 1.7508 sec\n",
            "Epoch 12 : [39744 / 40150] loss : 26.437633514404297, Batch time: 1.7358 sec\n",
            "Epoch 12 finished, Total Epoch time: 2989.7846 sec\n",
            "Epoch : 12, Loss : 33.627891385631195, Val_loss : 48.48928497411028\n",
            "Epoch 13 : [64 / 40150] loss : 23.214929580688477, Batch time: 1.7315 sec\n",
            "Epoch 13 : [704 / 40150] loss : 30.980545043945312, Batch time: 1.7446 sec\n",
            "Epoch 13 : [1344 / 40150] loss : 54.69051742553711, Batch time: 1.7253 sec\n",
            "Epoch 13 : [1984 / 40150] loss : 24.391178131103516, Batch time: 1.7536 sec\n",
            "Epoch 13 : [2624 / 40150] loss : 26.46990966796875, Batch time: 1.7443 sec\n",
            "Epoch 13 : [3264 / 40150] loss : 34.35143280029297, Batch time: 1.7554 sec\n",
            "Epoch 13 : [3904 / 40150] loss : 24.810047149658203, Batch time: 1.7459 sec\n",
            "Epoch 13 : [4544 / 40150] loss : 33.17700958251953, Batch time: 1.7616 sec\n",
            "Epoch 13 : [5184 / 40150] loss : 30.24733543395996, Batch time: 1.7572 sec\n",
            "Epoch 13 : [5824 / 40150] loss : 31.349403381347656, Batch time: 1.7620 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 : [6464 / 40150] loss : 25.525609970092773, Batch time: 1.7889 sec\n",
            "Epoch 13 : [7104 / 40150] loss : 25.569198608398438, Batch time: 1.7522 sec\n",
            "Epoch 13 : [7744 / 40150] loss : 22.512928009033203, Batch time: 1.7663 sec\n",
            "Epoch 13 : [8384 / 40150] loss : 26.23139762878418, Batch time: 1.7818 sec\n",
            "Epoch 13 : [9024 / 40150] loss : 36.2441520690918, Batch time: 1.7645 sec\n",
            "Epoch 13 : [9664 / 40150] loss : 31.853008270263672, Batch time: 1.7727 sec\n",
            "Epoch 13 : [10304 / 40150] loss : 55.403236389160156, Batch time: 1.7479 sec\n",
            "Epoch 13 : [10944 / 40150] loss : 29.43818473815918, Batch time: 1.7714 sec\n",
            "Epoch 13 : [11584 / 40150] loss : 28.72286033630371, Batch time: 1.7836 sec\n",
            "Epoch 13 : [12224 / 40150] loss : 25.07830810546875, Batch time: 1.7835 sec\n",
            "Epoch 13 : [12864 / 40150] loss : 24.822071075439453, Batch time: 1.7673 sec\n",
            "Epoch 13 : [13504 / 40150] loss : 36.05870819091797, Batch time: 1.7977 sec\n",
            "Epoch 13 : [14144 / 40150] loss : 19.2220516204834, Batch time: 1.7796 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 : [14784 / 40150] loss : 24.11465835571289, Batch time: 1.7458 sec\n",
            "Epoch 13 : [15424 / 40150] loss : 23.352338790893555, Batch time: 1.7839 sec\n",
            "Epoch 13 : [16064 / 40150] loss : 35.312408447265625, Batch time: 1.7763 sec\n",
            "Epoch 13 : [16704 / 40150] loss : 15.86916732788086, Batch time: 1.8230 sec\n",
            "Epoch 13 : [17344 / 40150] loss : 47.18305206298828, Batch time: 1.8403 sec\n",
            "Epoch 13 : [17984 / 40150] loss : 30.59844207763672, Batch time: 1.8249 sec\n",
            "Epoch 13 : [18624 / 40150] loss : 48.353355407714844, Batch time: 1.8367 sec\n",
            "Epoch 13 : [19264 / 40150] loss : 22.91344451904297, Batch time: 1.8201 sec\n",
            "Epoch 13 : [19904 / 40150] loss : 30.083328247070312, Batch time: 1.8255 sec\n",
            "Epoch 13 : [20544 / 40150] loss : 29.23086166381836, Batch time: 1.8359 sec\n",
            "Epoch 13 : [21184 / 40150] loss : 26.505874633789062, Batch time: 1.8628 sec\n",
            "Epoch 13 : [21824 / 40150] loss : 28.83131980895996, Batch time: 1.8422 sec\n",
            "Epoch 13 : [22464 / 40150] loss : 23.743576049804688, Batch time: 1.8371 sec\n",
            "Epoch 13 : [23104 / 40150] loss : 28.32906723022461, Batch time: 1.7886 sec\n",
            "Epoch 13 : [23744 / 40150] loss : 29.451990127563477, Batch time: 1.8517 sec\n",
            "Epoch 13 : [24384 / 40150] loss : 32.195674896240234, Batch time: 1.7898 sec\n",
            "Epoch 13 : [25024 / 40150] loss : 34.38311767578125, Batch time: 1.8185 sec\n",
            "Epoch 13 : [25664 / 40150] loss : 23.986351013183594, Batch time: 1.8304 sec\n",
            "Epoch 13 : [26304 / 40150] loss : 18.511066436767578, Batch time: 1.7956 sec\n",
            "Epoch 13 : [26944 / 40150] loss : 30.165409088134766, Batch time: 1.7902 sec\n",
            "Epoch 13 : [27584 / 40150] loss : 43.21616744995117, Batch time: 1.8045 sec\n",
            "Epoch 13 : [28224 / 40150] loss : 32.905616760253906, Batch time: 1.8010 sec\n",
            "Epoch 13 : [28864 / 40150] loss : 26.606107711791992, Batch time: 1.8223 sec\n",
            "Epoch 13 : [29504 / 40150] loss : 22.00325584411621, Batch time: 1.8128 sec\n",
            "Epoch 13 : [30144 / 40150] loss : 50.46226501464844, Batch time: 1.8036 sec\n",
            "Epoch 13 : [30784 / 40150] loss : 21.508502960205078, Batch time: 1.7916 sec\n",
            "Epoch 13 : [31424 / 40150] loss : 53.8177490234375, Batch time: 1.8095 sec\n",
            "Epoch 13 : [32064 / 40150] loss : 28.80804443359375, Batch time: 1.8452 sec\n",
            "Epoch 13 : [32704 / 40150] loss : 31.25187873840332, Batch time: 1.7976 sec\n",
            "Epoch 13 : [33344 / 40150] loss : 23.88447380065918, Batch time: 1.8428 sec\n",
            "Epoch 13 : [33984 / 40150] loss : 29.286375045776367, Batch time: 1.7902 sec\n",
            "Epoch 13 : [34624 / 40150] loss : 24.979257583618164, Batch time: 1.8130 sec\n",
            "Epoch 13 : [35264 / 40150] loss : 24.60940170288086, Batch time: 1.8349 sec\n",
            "Epoch 13 : [35904 / 40150] loss : 26.101980209350586, Batch time: 1.7933 sec\n",
            "Epoch 13 : [36544 / 40150] loss : 31.67523193359375, Batch time: 1.8159 sec\n",
            "Epoch 13 : [37184 / 40150] loss : 23.66861343383789, Batch time: 1.7959 sec\n",
            "Epoch 13 : [37824 / 40150] loss : 57.593868255615234, Batch time: 1.8111 sec\n",
            "Epoch 13 : [38464 / 40150] loss : 19.626590728759766, Batch time: 1.8073 sec\n",
            "Epoch 13 : [39104 / 40150] loss : 41.39086151123047, Batch time: 1.8052 sec\n",
            "Epoch 13 : [39744 / 40150] loss : 50.80512237548828, Batch time: 1.8000 sec\n",
            "Epoch 13 finished, Total Epoch time: 3024.8009 sec\n",
            "Epoch : 13, Loss : 31.059670966142303, Val_loss : 51.898619048203095\n",
            "Epoch 14 : [64 / 40150] loss : 29.78453254699707, Batch time: 1.8325 sec\n",
            "Epoch 14 : [704 / 40150] loss : 24.008710861206055, Batch time: 1.8381 sec\n",
            "Epoch 14 : [1344 / 40150] loss : 24.27849578857422, Batch time: 1.7974 sec\n",
            "Epoch 14 : [1984 / 40150] loss : 21.75740623474121, Batch time: 1.8109 sec\n",
            "Epoch 14 : [2624 / 40150] loss : 26.578609466552734, Batch time: 1.7969 sec\n",
            "Epoch 14 : [3264 / 40150] loss : 20.462158203125, Batch time: 1.7827 sec\n",
            "Epoch 14 : [3904 / 40150] loss : 25.656509399414062, Batch time: 1.8120 sec\n",
            "Epoch 14 : [4544 / 40150] loss : 25.287090301513672, Batch time: 1.8064 sec\n",
            "Epoch 14 : [5184 / 40150] loss : 22.428997039794922, Batch time: 1.8054 sec\n",
            "Epoch 14 : [5824 / 40150] loss : 36.163482666015625, Batch time: 1.7923 sec\n",
            "Epoch 14 : [6464 / 40150] loss : 47.11934280395508, Batch time: 1.7966 sec\n",
            "Epoch 14 : [7104 / 40150] loss : 24.484357833862305, Batch time: 1.8185 sec\n",
            "Epoch 14 : [7744 / 40150] loss : 30.6007080078125, Batch time: 1.7942 sec\n",
            "Epoch 14 : [8384 / 40150] loss : 20.920005798339844, Batch time: 1.7965 sec\n",
            "Epoch 14 : [9024 / 40150] loss : 26.844600677490234, Batch time: 1.8336 sec\n",
            "Epoch 14 : [9664 / 40150] loss : 26.296127319335938, Batch time: 1.8120 sec\n",
            "Epoch 14 : [10304 / 40150] loss : 25.65925407409668, Batch time: 1.7942 sec\n",
            "Epoch 14 : [10944 / 40150] loss : 34.09611511230469, Batch time: 1.8165 sec\n",
            "Epoch 14 : [11584 / 40150] loss : 23.524559020996094, Batch time: 1.7918 sec\n",
            "Epoch 14 : [12224 / 40150] loss : 31.993968963623047, Batch time: 1.8057 sec\n",
            "Epoch 14 : [12864 / 40150] loss : 24.394065856933594, Batch time: 1.7948 sec\n",
            "Epoch 14 : [13504 / 40150] loss : 37.216705322265625, Batch time: 1.8135 sec\n",
            "Epoch 14 : [14144 / 40150] loss : 17.84775161743164, Batch time: 1.8452 sec\n",
            "Epoch 14 : [14784 / 40150] loss : 28.953590393066406, Batch time: 1.8189 sec\n",
            "Epoch 14 : [15424 / 40150] loss : 23.187175750732422, Batch time: 1.8045 sec\n",
            "Epoch 14 : [16064 / 40150] loss : 22.94835090637207, Batch time: 1.8075 sec\n",
            "Epoch 14 : [16704 / 40150] loss : 21.549488067626953, Batch time: 1.8279 sec\n",
            "Epoch 14 : [17344 / 40150] loss : 23.63239097595215, Batch time: 1.8226 sec\n",
            "Epoch 14 : [17984 / 40150] loss : 25.249914169311523, Batch time: 1.8417 sec\n",
            "Epoch 14 : [18624 / 40150] loss : 24.173229217529297, Batch time: 1.8209 sec\n",
            "Epoch 14 : [19264 / 40150] loss : 23.136085510253906, Batch time: 1.8390 sec\n",
            "Epoch 14 : [19904 / 40150] loss : 20.602394104003906, Batch time: 1.8410 sec\n",
            "Epoch 14 : [20544 / 40150] loss : 23.798925399780273, Batch time: 1.7988 sec\n",
            "Epoch 14 : [21184 / 40150] loss : 27.052989959716797, Batch time: 1.8271 sec\n",
            "Epoch 14 : [21824 / 40150] loss : 14.417428970336914, Batch time: 1.8252 sec\n",
            "Epoch 14 : [22464 / 40150] loss : 26.230329513549805, Batch time: 1.8233 sec\n",
            "Epoch 14 : [23104 / 40150] loss : 26.271408081054688, Batch time: 1.8185 sec\n",
            "Epoch 14 : [23744 / 40150] loss : 27.11056137084961, Batch time: 1.8041 sec\n",
            "Epoch 14 : [24384 / 40150] loss : 21.383459091186523, Batch time: 1.8225 sec\n",
            "Epoch 14 : [25024 / 40150] loss : 27.275615692138672, Batch time: 1.8408 sec\n",
            "Epoch 14 : [25664 / 40150] loss : 25.36417579650879, Batch time: 1.8344 sec\n",
            "Epoch 14 : [26304 / 40150] loss : 21.263612747192383, Batch time: 1.8252 sec\n",
            "Epoch 14 : [26944 / 40150] loss : 40.695613861083984, Batch time: 1.8397 sec\n",
            "Epoch 14 : [27584 / 40150] loss : 34.943538665771484, Batch time: 1.8218 sec\n",
            "Epoch 14 : [28224 / 40150] loss : 27.403564453125, Batch time: 1.8716 sec\n",
            "Epoch 14 : [28864 / 40150] loss : 42.42145919799805, Batch time: 1.8212 sec\n",
            "Epoch 14 : [29504 / 40150] loss : 31.06353759765625, Batch time: 1.8384 sec\n",
            "Epoch 14 : [30144 / 40150] loss : 39.75868225097656, Batch time: 1.8147 sec\n",
            "Epoch 14 : [30784 / 40150] loss : 31.778318405151367, Batch time: 1.8378 sec\n",
            "Epoch 14 : [31424 / 40150] loss : 21.113548278808594, Batch time: 1.8296 sec\n",
            "Epoch 14 : [32064 / 40150] loss : 23.91480255126953, Batch time: 1.8519 sec\n",
            "Epoch 14 : [32704 / 40150] loss : 39.416053771972656, Batch time: 1.8395 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 : [33344 / 40150] loss : 33.43273162841797, Batch time: 1.8535 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 : [33984 / 40150] loss : 24.89082145690918, Batch time: 1.8180 sec\n",
            "Epoch 14 : [34624 / 40150] loss : 27.422351837158203, Batch time: 1.8415 sec\n",
            "Epoch 14 : [35264 / 40150] loss : 37.34911346435547, Batch time: 1.8291 sec\n",
            "Epoch 14 : [35904 / 40150] loss : 30.30063247680664, Batch time: 1.8503 sec\n",
            "Epoch 14 : [36544 / 40150] loss : 40.22540283203125, Batch time: 1.8148 sec\n",
            "Epoch 14 : [37184 / 40150] loss : 31.748165130615234, Batch time: 1.8150 sec\n",
            "Epoch 14 : [37824 / 40150] loss : 27.97020721435547, Batch time: 1.8197 sec\n",
            "Epoch 14 : [38464 / 40150] loss : 26.59662628173828, Batch time: 1.8211 sec\n",
            "Epoch 14 : [39104 / 40150] loss : 30.77665138244629, Batch time: 1.8226 sec\n",
            "Epoch 14 : [39744 / 40150] loss : 15.491265296936035, Batch time: 1.8319 sec\n",
            "Epoch 14 finished, Total Epoch time: 2889.4244 sec\n",
            "Epoch : 14, Loss : 28.95467392198599, Val_loss : 48.438780072369156\n",
            "Epoch 15 : [64 / 40150] loss : 22.69908905029297, Batch time: 1.7023 sec\n",
            "Epoch 15 : [704 / 40150] loss : 22.05562973022461, Batch time: 1.6805 sec\n",
            "Epoch 15 : [1344 / 40150] loss : 39.235679626464844, Batch time: 1.7350 sec\n",
            "Epoch 15 : [1984 / 40150] loss : 18.138469696044922, Batch time: 1.7356 sec\n",
            "Epoch 15 : [2624 / 40150] loss : 25.632265090942383, Batch time: 1.6699 sec\n",
            "Epoch 15 : [3264 / 40150] loss : 24.32261848449707, Batch time: 1.6951 sec\n",
            "Epoch 15 : [3904 / 40150] loss : 33.985084533691406, Batch time: 1.6755 sec\n",
            "Epoch 15 : [4544 / 40150] loss : 27.907033920288086, Batch time: 1.6802 sec\n",
            "Epoch 15 : [5184 / 40150] loss : 15.569622039794922, Batch time: 1.6923 sec\n",
            "Epoch 15 : [5824 / 40150] loss : 22.965442657470703, Batch time: 1.6677 sec\n",
            "Epoch 15 : [6464 / 40150] loss : 28.91568374633789, Batch time: 1.6696 sec\n",
            "Epoch 15 : [7104 / 40150] loss : 31.11562728881836, Batch time: 1.6974 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 : [7744 / 40150] loss : 29.098098754882812, Batch time: 1.7618 sec\n",
            "Epoch 15 : [8384 / 40150] loss : 21.43895721435547, Batch time: 1.7741 sec\n",
            "Epoch 15 : [9024 / 40150] loss : 18.96926498413086, Batch time: 1.8161 sec\n",
            "Epoch 15 : [9664 / 40150] loss : 27.68683433532715, Batch time: 1.8036 sec\n",
            "Epoch 15 : [10304 / 40150] loss : 28.271503448486328, Batch time: 1.8381 sec\n",
            "Epoch 15 : [10944 / 40150] loss : 26.09821891784668, Batch time: 1.8117 sec\n",
            "Epoch 15 : [11584 / 40150] loss : 23.60952377319336, Batch time: 1.8081 sec\n",
            "Epoch 15 : [12224 / 40150] loss : 29.241058349609375, Batch time: 1.7701 sec\n",
            "Epoch 15 : [12864 / 40150] loss : 27.679889678955078, Batch time: 1.8071 sec\n",
            "Epoch 15 : [13504 / 40150] loss : 42.434268951416016, Batch time: 1.7455 sec\n",
            "Epoch 15 : [14144 / 40150] loss : 20.566181182861328, Batch time: 1.7248 sec\n",
            "Epoch 15 : [14784 / 40150] loss : 33.84473419189453, Batch time: 1.7266 sec\n",
            "Epoch 15 : [15424 / 40150] loss : 24.68648910522461, Batch time: 1.7352 sec\n",
            "Epoch 15 : [16064 / 40150] loss : 28.567819595336914, Batch time: 1.7454 sec\n",
            "Epoch 15 : [16704 / 40150] loss : 20.449588775634766, Batch time: 1.6830 sec\n",
            "Epoch 15 : [17344 / 40150] loss : 29.628372192382812, Batch time: 1.6841 sec\n",
            "Epoch 15 : [17984 / 40150] loss : 22.777666091918945, Batch time: 1.6677 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 : [18624 / 40150] loss : 28.493064880371094, Batch time: 1.6580 sec\n",
            "Epoch 15 : [19264 / 40150] loss : 24.080921173095703, Batch time: 1.6573 sec\n",
            "Epoch 15 : [19904 / 40150] loss : 13.415287971496582, Batch time: 1.7353 sec\n",
            "Epoch 15 : [20544 / 40150] loss : 26.49669647216797, Batch time: 1.6873 sec\n",
            "Epoch 15 : [21184 / 40150] loss : 21.77327537536621, Batch time: 1.6796 sec\n",
            "Epoch 15 : [21824 / 40150] loss : 30.151508331298828, Batch time: 1.6756 sec\n",
            "Epoch 15 : [22464 / 40150] loss : 23.37619972229004, Batch time: 1.6849 sec\n",
            "Epoch 15 : [23104 / 40150] loss : 27.62038803100586, Batch time: 1.6747 sec\n",
            "Epoch 15 : [23744 / 40150] loss : 21.897462844848633, Batch time: 1.6921 sec\n",
            "Epoch 15 : [24384 / 40150] loss : 14.183609962463379, Batch time: 1.7153 sec\n",
            "Epoch 15 : [25024 / 40150] loss : 20.420272827148438, Batch time: 1.6742 sec\n",
            "Epoch 15 : [25664 / 40150] loss : 33.19867706298828, Batch time: 1.7193 sec\n",
            "Epoch 15 : [26304 / 40150] loss : 39.24749755859375, Batch time: 1.6742 sec\n",
            "Epoch 15 : [26944 / 40150] loss : 17.821502685546875, Batch time: 1.7025 sec\n",
            "Epoch 15 : [27584 / 40150] loss : 32.845951080322266, Batch time: 1.7081 sec\n",
            "Epoch 15 : [28224 / 40150] loss : 28.23706817626953, Batch time: 1.7711 sec\n",
            "Epoch 15 : [28864 / 40150] loss : 28.466781616210938, Batch time: 1.6850 sec\n",
            "Epoch 15 : [29504 / 40150] loss : 31.905166625976562, Batch time: 1.6867 sec\n",
            "Epoch 15 : [30144 / 40150] loss : 27.88773536682129, Batch time: 1.7114 sec\n",
            "Epoch 15 : [30784 / 40150] loss : 19.84085464477539, Batch time: 1.7424 sec\n",
            "Epoch 15 : [31424 / 40150] loss : 18.947025299072266, Batch time: 1.7398 sec\n",
            "Epoch 15 : [32064 / 40150] loss : 15.956794738769531, Batch time: 1.6952 sec\n",
            "Epoch 15 : [32704 / 40150] loss : 25.550764083862305, Batch time: 1.6953 sec\n",
            "Epoch 15 : [33344 / 40150] loss : 23.03218650817871, Batch time: 1.6900 sec\n",
            "Epoch 15 : [33984 / 40150] loss : 25.934253692626953, Batch time: 1.6646 sec\n",
            "Epoch 15 : [34624 / 40150] loss : 14.435689926147461, Batch time: 1.6607 sec\n",
            "Epoch 15 : [35264 / 40150] loss : 23.34588050842285, Batch time: 1.7122 sec\n",
            "Epoch 15 : [35904 / 40150] loss : 19.754161834716797, Batch time: 1.7218 sec\n",
            "Epoch 15 : [36544 / 40150] loss : 27.011173248291016, Batch time: 1.6886 sec\n",
            "Epoch 15 : [37184 / 40150] loss : 24.606271743774414, Batch time: 1.6711 sec\n",
            "Epoch 15 : [37824 / 40150] loss : 22.059480667114258, Batch time: 1.6800 sec\n",
            "Epoch 15 : [38464 / 40150] loss : 25.5493106842041, Batch time: 1.6756 sec\n",
            "Epoch 15 : [39104 / 40150] loss : 24.080951690673828, Batch time: 1.7087 sec\n",
            "Epoch 15 : [39744 / 40150] loss : 31.017295837402344, Batch time: 1.6696 sec\n",
            "Epoch 15 finished, Total Epoch time: 2874.7238 sec\n",
            "Epoch : 15, Loss : 26.666760903255195, Val_loss : 49.81154549272755\n",
            "Epoch 16 : [64 / 40150] loss : 35.533477783203125, Batch time: 1.7150 sec\n",
            "Epoch 16 : [704 / 40150] loss : 30.006244659423828, Batch time: 1.7334 sec\n",
            "Epoch 16 : [1344 / 40150] loss : 17.20899772644043, Batch time: 1.7247 sec\n",
            "Epoch 16 : [1984 / 40150] loss : 23.07265281677246, Batch time: 1.6664 sec\n",
            "Epoch 16 : [2624 / 40150] loss : 25.318340301513672, Batch time: 1.6543 sec\n",
            "Epoch 16 : [3264 / 40150] loss : 23.89349937438965, Batch time: 1.6695 sec\n",
            "Epoch 16 : [3904 / 40150] loss : 28.732311248779297, Batch time: 1.6954 sec\n",
            "Epoch 16 : [4544 / 40150] loss : 21.17730140686035, Batch time: 1.6698 sec\n",
            "Epoch 16 : [5184 / 40150] loss : 20.63784408569336, Batch time: 1.6805 sec\n",
            "Epoch 16 : [5824 / 40150] loss : 21.091659545898438, Batch time: 1.6674 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 : [6464 / 40150] loss : 27.20549774169922, Batch time: 1.6992 sec\n",
            "Epoch 16 : [7104 / 40150] loss : 16.421920776367188, Batch time: 1.7656 sec\n",
            "Epoch 16 : [7744 / 40150] loss : 14.774759292602539, Batch time: 1.7897 sec\n",
            "Epoch 16 : [8384 / 40150] loss : 21.49358558654785, Batch time: 1.7894 sec\n",
            "Epoch 16 : [9024 / 40150] loss : 22.397260665893555, Batch time: 1.7943 sec\n",
            "Epoch 16 : [9664 / 40150] loss : 20.811403274536133, Batch time: 1.8275 sec\n",
            "Epoch 16 : [10304 / 40150] loss : 17.684261322021484, Batch time: 1.8159 sec\n",
            "Epoch 16 : [10944 / 40150] loss : 31.81106185913086, Batch time: 1.8083 sec\n",
            "Epoch 16 : [11584 / 40150] loss : 21.407276153564453, Batch time: 1.7990 sec\n",
            "Epoch 16 : [12224 / 40150] loss : 36.502685546875, Batch time: 1.8175 sec\n",
            "Epoch 16 : [12864 / 40150] loss : 12.487272262573242, Batch time: 1.7974 sec\n",
            "Epoch 16 : [13504 / 40150] loss : 21.930740356445312, Batch time: 1.8248 sec\n",
            "Epoch 16 : [14144 / 40150] loss : 19.30422592163086, Batch time: 1.8091 sec\n",
            "Epoch 16 : [14784 / 40150] loss : 21.167444229125977, Batch time: 1.8088 sec\n",
            "Epoch 16 : [15424 / 40150] loss : 24.89957046508789, Batch time: 1.8308 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:3167: DecompressionBombWarning: Image size (133505320 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 : [16064 / 40150] loss : 16.196388244628906, Batch time: 1.8230 sec\n",
            "Epoch 16 : [16704 / 40150] loss : 17.8514404296875, Batch time: 1.8069 sec\n",
            "Epoch 16 : [17344 / 40150] loss : 22.1536808013916, Batch time: 1.7963 sec\n",
            "Epoch 16 : [17984 / 40150] loss : 19.58378791809082, Batch time: 1.7871 sec\n",
            "Epoch 16 : [18624 / 40150] loss : 25.387161254882812, Batch time: 1.7961 sec\n",
            "Epoch 16 : [19264 / 40150] loss : 20.077302932739258, Batch time: 1.8073 sec\n",
            "Epoch 16 : [19904 / 40150] loss : 27.32141876220703, Batch time: 1.8177 sec\n",
            "Epoch 16 : [20544 / 40150] loss : 22.887775421142578, Batch time: 1.8139 sec\n",
            "Epoch 16 : [21184 / 40150] loss : 18.911575317382812, Batch time: 1.8177 sec\n",
            "Epoch 16 : [21824 / 40150] loss : 36.678955078125, Batch time: 1.7917 sec\n",
            "Epoch 16 : [22464 / 40150] loss : 21.196876525878906, Batch time: 1.7777 sec\n",
            "Epoch 16 : [23104 / 40150] loss : 26.73309326171875, Batch time: 1.7965 sec\n",
            "Epoch 16 : [23744 / 40150] loss : 29.107816696166992, Batch time: 1.8133 sec\n",
            "Epoch 16 : [24384 / 40150] loss : 37.761558532714844, Batch time: 1.8108 sec\n",
            "Epoch 16 : [25024 / 40150] loss : 17.18840789794922, Batch time: 1.7984 sec\n",
            "Epoch 16 : [25664 / 40150] loss : 19.108015060424805, Batch time: 1.7881 sec\n",
            "Epoch 16 : [26304 / 40150] loss : 17.715065002441406, Batch time: 1.8021 sec\n",
            "Epoch 16 : [26944 / 40150] loss : 38.77846908569336, Batch time: 1.7985 sec\n",
            "Epoch 16 : [27584 / 40150] loss : 25.05071258544922, Batch time: 1.8222 sec\n",
            "Epoch 16 : [28224 / 40150] loss : 22.390457153320312, Batch time: 1.7956 sec\n",
            "Epoch 16 : [28864 / 40150] loss : 36.29810333251953, Batch time: 1.8001 sec\n",
            "Epoch 16 : [29504 / 40150] loss : 35.88821029663086, Batch time: 1.7938 sec\n",
            "Epoch 16 : [30144 / 40150] loss : 20.789865493774414, Batch time: 1.7950 sec\n",
            "Epoch 16 : [30784 / 40150] loss : 23.69278335571289, Batch time: 1.8272 sec\n",
            "Epoch 16 : [31424 / 40150] loss : 15.437870025634766, Batch time: 1.7994 sec\n",
            "Epoch 16 : [32064 / 40150] loss : 30.210460662841797, Batch time: 1.7838 sec\n",
            "Epoch 16 : [32704 / 40150] loss : 21.347728729248047, Batch time: 1.8096 sec\n",
            "Epoch 16 : [33344 / 40150] loss : 21.01171875, Batch time: 1.7859 sec\n",
            "Epoch 16 : [33984 / 40150] loss : 46.888343811035156, Batch time: 1.8284 sec\n",
            "Epoch 16 : [34624 / 40150] loss : 22.487102508544922, Batch time: 1.7921 sec\n",
            "Epoch 16 : [35264 / 40150] loss : 14.597186088562012, Batch time: 1.8002 sec\n",
            "Epoch 16 : [35904 / 40150] loss : 18.838991165161133, Batch time: 1.8132 sec\n",
            "Epoch 16 : [36544 / 40150] loss : 20.958717346191406, Batch time: 1.8057 sec\n",
            "Epoch 16 : [37184 / 40150] loss : 29.817655563354492, Batch time: 1.8140 sec\n",
            "Epoch 16 : [37824 / 40150] loss : 27.393104553222656, Batch time: 1.7955 sec\n",
            "Epoch 16 : [38464 / 40150] loss : 18.650772094726562, Batch time: 1.7765 sec\n",
            "Epoch 16 : [39104 / 40150] loss : 15.221445083618164, Batch time: 1.8376 sec\n",
            "Epoch 16 : [39744 / 40150] loss : 18.785856246948242, Batch time: 1.7979 sec\n",
            "Epoch 16 finished, Total Epoch time: 2886.3114 sec\n",
            "Epoch : 16, Loss : 24.51864461989919, Val_loss : 43.89916703067249\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-614d8cb1df11>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mage_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_loop_age\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mage_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-5763b9d00070>\u001b[0m in \u001b[0;36mtrain_loop_age\u001b[0;34m(dataloader, model, loss_fn, optimizer, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 에포크 시작 시간\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 배치 처리 시작 시간\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'age_past'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 모델과 옵티마이저 초기화\n",
        "age_model = Age_Net().to(device)\n",
        "opt_age = optim.Adam(age_model.parameters(), lr=0.0003)\n",
        "\n",
        "# 체크포인트 불러오기\n",
        "age_model, opt_age, start_epoch = load_model(age_model, opt_age, '/content/drive/MyDrive/DL_DATA/Model/norm_batch/age_model_checkpoint_epoch_11.pth')\n",
        "\n",
        "# 학습 재개\n",
        "start = time.time()\n",
        "for epoch in range(start_epoch + 1, start_epoch + 28):\n",
        "    age_loss = train_loop_age(train_loader, age_model, nn.MSELoss(), opt_age, epoch)\n",
        "    val_loss = validation_loop_age(val_loader, age_model, nn.MSELoss(), device)\n",
        "    age_lr_scheduler.step(val_loss)\n",
        "\n",
        "    early_stopping(val_loss)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        save_model(epoch, age_model, opt_age, '/content/drive/MyDrive/DL_DATA/Model/norm_batch/age_model_checkpoint.pth')\n",
        "        break\n",
        "\n",
        "    save_model(epoch, age_model, opt_age, f'/content/drive/MyDrive/DL_DATA/Model/norm_batch/age_model_checkpoint_epoch_{epoch+1}.pth')\n",
        "    print(f'Epoch : {epoch + 1}, Loss : {age_loss}, Val_loss : {val_loss}')\n",
        "\n",
        "total_time = time.time() - start\n",
        "\n",
        "hours, rem = divmod(total_time, 3600)\n",
        "minutes, seconds = divmod(rem, 60)\n",
        "print(\"Total training time: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ7hC1KBgo8H"
      },
      "source": [
        "- Epoch : 1, Loss : 183.76921428333628, Val_loss : 138.7342578125\n",
        "- Epoch : 2, Loss : 128.2447030203683, Val_loss : 143.2067679595947\n",
        "- Epoch : 3, Loss : 122.56000444965977, Val_loss : 96.83059211730956\n",
        "- Epoch : 4, Loss : 87.70850903081437, Val_loss : 78.38082936604818\n",
        "- Epoch : 5, Loss : 68.04693739406598, Val_loss : 72.64038126627604\n",
        "- Epoch : 6, Loss : 57.276853927027304, Val_loss : 68.96054336547851\n",
        "- Epoch : 7, Loss : 51.59112667961242, Val_loss : 57.317286516825355\n",
        "- Epoch : 8, Loss : 47.01944582150006, Val_loss : 55.66085670471191\n",
        "- Epoch : 9, Loss : 42.54086226624803, Val_loss : 53.47876875559489\n",
        "- Epoch : 10, Loss : 39.80607411198723, Val_loss : 54.47281494140625\n",
        "- Epoch : 11, Loss : 36.430880546569824, Val_loss : 54.80409914652507\n",
        "- Epoch : 12, Loss : 33.627891385631195, Val_loss : 48.48928497411028\n",
        "- Epoch : 13, Loss : 31.059670966142303, Val_loss : 51.898619048203095\n",
        "- Epoch : 14, Loss : 28.95467392198599, Val_loss : 48.438780072369156\n",
        "- Epoch : 15, Loss : 26.666760903255195, Val_loss : 49.81154549272755\n",
        "- Epoch : 16, Loss : 24.51864461989919, Val_loss : 43.89916703067249"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DysRMF7v1Tdi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_9ev89ytknF"
      },
      "outputs": [],
      "source": [
        "def train_loop_gender(dataloader, model, loss_fn, optimizer, epoch):\n",
        "    model.train()\n",
        "    size = len(dataloader.dataset)\n",
        "    total_loss = 0.0\n",
        "    start_time = time.time()  # 에포크 시작 시간\n",
        "\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        batch_start_time = time.time()  # 배치 처리 시작 시간\n",
        "        x, y = x.to(device), y['gender'].float().to(device)\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred.squeeze(), y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_process_time = time.time() - batch_start_time\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            processed = (batch + 1) * len(x)\n",
        "            print(f'Epoch {epoch+1} : [{processed} / {size}] loss : {loss.item()}, Batch time: {batch_process_time:.4f} sec')\n",
        "\n",
        "    average_loss = total_loss / len(dataloader)\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    print(f\"Epoch {epoch+1} finished, Total Epoch time: {epoch_time:.4f} sec\")\n",
        "    return average_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poLyFmi-kYey"
      },
      "outputs": [],
      "source": [
        "def validation_loop_gender(dataloader, model, loss_fn, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            x, y = x.to(device), y['gender'].float().to(device)\n",
        "            pred = model(x)\n",
        "            loss = loss_fn(pred, y)\n",
        "            val_loss += loss.item()\n",
        "    val_loss /= len(dataloader)\n",
        "    return val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOfo7N6gkeyj"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "for epoch in range(30):\n",
        "    gender_loss = train_loop_gender(train_loader, gender_model, nn.BCEWithLogitsLoss(), opt_gender, epoch)\n",
        "    val_loss = validation_loop_gender(val_loader, gender_model, nn.BCEWithLogitsLoss(), device)\n",
        "    gender_lr_scheduler.step(val_loss)\n",
        "    early_stopping(val_loss)\n",
        "\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping triggered\")\n",
        "        save_model(epoch, gender_model, opt_gender, '/content/drive/MyDrive/DL_DATA/Model/gender_model_checkpoint.pth')\n",
        "        break\n",
        "\n",
        "    save_model(epoch, gender_model, opt_gender, f'/content/drive/MyDrive/DL_DATA/Model/gender_model_checkpoint_epoch_{epoch+1}.pth')\n",
        "    print(f'Epoch : {epoch+1}, Loss : {gender_loss}, Val_loss : {val_loss}')\n",
        "\n",
        "total_time = time.time() - start\n",
        "hours, rem = divmod(total_time, 3600)\n",
        "minutes, seconds = divmod(rem, 60)\n",
        "print(\"Total training time: {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvIVaw61zi8p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "0.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
