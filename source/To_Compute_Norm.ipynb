{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    \"\"\"\n",
    "    모든 랜덤 시드를 주어진 값으로 고정합니다.\n",
    "    \"\"\"\n",
    "    random.seed(seed)  # Python random 모듈\n",
    "    np.random.seed(seed)  # Numpy 랜덤 시드\n",
    "    torch.manual_seed(seed)  # PyTorch 랜덤 시드\n",
    "    torch.cuda.manual_seed(seed)  # GPU를 위한 PyTorch 랜덤 시드\n",
    "    torch.cuda.manual_seed_all(seed)  # 멀티 GPU를 위한 PyTorch 랜덤 시드\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규화를 위한 데이터셋 이미지들의 RGB 평균과 표준편차 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetNorm(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_root, label_root, transform=None, sample_size=None):\n",
    "        self.data_root = data_root\n",
    "        self.label_root = label_root\n",
    "        self.transform = transform\n",
    "        self.data_paths = glob.glob(os.path.join(data_root, '*/*.png'))\n",
    "        self.label_paths = [path.replace('.png', '.json').replace(data_root, label_root) for path in self.data_paths]\n",
    "        \n",
    "        if sample_size and sample_size < len(self.data_paths):\n",
    "            sampled_indices = random.sample(range(len(self.data_paths)), sample_size)\n",
    "            self.data_paths = [self.data_paths[i] for i in sampled_indices]\n",
    "            self.label_paths = [self.label_paths[i] for i in sampled_indices]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.data_paths[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        label_path = self.label_paths[index]\n",
    "        with open(label_path, 'r') as f:\n",
    "            label_data = json.load(f)\n",
    "            \n",
    "        box = label_data['annotation'][0]['box']\n",
    "        image = image.crop((box['x'], box['y'], box['x'] + box['w'], box['y'] + box['h']))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "dataset = DatasetNorm(data_root='./dataset/train/images', label_root='./dataset/train/labels', transform=transform)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=256, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\torch\\lib\\site-packages\\PIL\\Image.py:3186: DecompressionBombWarning: Image size (108000000 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.6284, 0.4901, 0.4325]), Std: tensor([0.1869, 0.1712, 0.1561])\n"
     ]
    }
   ],
   "source": [
    "def calculate_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "    \n",
    "    for images in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += batch_samples\n",
    "    \n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "    \n",
    "    return mean, std\n",
    "\n",
    "# 평균과 표준편차 계산\n",
    "mean, std = calculate_mean_std(loader)\n",
    "print(f\"Mean: {mean}, Std: {std}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean: tensor([0.6230, 0.4818, 0.4254]), Std: tensor([0.1833, 0.1669, 0.1501]) - sample_size 100\n",
    "- Mean: tensor([0.6259, 0.4877, 0.4292]), Std: tensor([0.1858, 0.1693, 0.1545]) - sample_size 1000\n",
    "- Mean: tensor([0.6285, 0.4912, 0.4342]), Std: tensor([0.1867, 0.1710, 0.1561]) - sample_size 10000\n",
    "- Mean: tensor([0.6284, 0.4901, 0.4325]), Std: tensor([0.1869, 0.1712, 0.1561]) - total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
